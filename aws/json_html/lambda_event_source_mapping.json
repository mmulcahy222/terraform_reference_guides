{"resource-aws-lambda-event-source-mapping": "<h1 id=\"resource-aws_lambda_event_source_mapping\">Resource: aws_lambda_event_source_mapping</h1><p>Provides a Lambda event source mapping. This allows Lambda functions to get events from Kinesis, DynamoDB, SQS, Amazon MQ and Managed Streaming for Apache Kafka (MSK).</p><p>For information about Lambda and how to use it, see <a href=\"http://docs.aws.amazon.com/lambda/latest/dg/welcome.html\">What is AWS Lambda?</a>.<br />For information about event source mappings, see <a href=\"http://docs.aws.amazon.com/lambda/latest/dg/API_CreateEventSourceMapping.html\">CreateEventSourceMapping</a> in the API docs.</p>", "example-usage": "<h2 id=\"example-usage\">Example Usage</h2><h3 id=\"dynamodb\">DynamoDB</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  event_source_arn  = aws_dynamodb_table.example.stream_arn<br />  function_name     = aws_lambda_function.example.arn<br />  starting_position = \"LATEST\"<br />}</p><br /><h3 id=\"kinesis\">Kinesis</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  event_source_arn  = aws_kinesis_stream.example.arn<br />  function_name     = aws_lambda_function.example.arn<br />  starting_position = \"LATEST\"<br />}</p><br /><h3 id=\"managed-streaming-for-apache-kafka-msk\">Managed Streaming for Apache Kafka (MSK)</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  event_source_arn  = aws_msk_cluster.example.arn<br />  function_name     = aws_lambda_function.example.arn<br />  topics            = [\"Example\"]<br />  starting_position = \"TRIM_HORIZON\"<br />}</p><br /><h3 id=\"self-managed-apache-kafka\">Self Managed Apache Kafka</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  function_name     = aws_lambda_function.example.arn<br />  topics            = [\"Example\"]<br />  starting_position = \"TRIM_HORIZON\"</p><br /><p>self_managed_event_source {<br />    endpoints = {<br />      KAFKA_BOOTSTRAP_SERVERS = \"kafka1.example.com:9092,kafka2.example.com:9092\"<br />    }<br />  }</p><br /><p>source_access_configuration {<br />    type = \"VPC_SUBNET\"<br />    uri  = \"subnet:subnet-example1\"<br />  }</p><br /><p>source_access_configuration {<br />    type = \"VPC_SUBNET\"<br />    uri  = \"subnet:subnet-example2\"<br />  }</p><br /><p>source_access_configuration {<br />    type = \"VPC_SECURITY_GROUP\"<br />    uri  = \"security_group:sg-example\"<br />  }<br />}</p><br /><h3 id=\"sqs\">SQS</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  event_source_arn = aws_sqs_queue.sqs_queue_test.arn<br />  function_name    = aws_lambda_function.example.arn<br />}</p><br /><h3 id=\"sqs-with-event-filter\">SQS with event filter</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  event_source_arn = aws_sqs_queue.sqs_queue_test.arn<br />  function_name    = aws_lambda_function.example.arn</p><br /><p>filter_criteria {<br />    filter {<br />      pattern = jsonencode({<br />        body = {<br />          Temperature : [{ numeric : [\"&gt;\", 0, \"&lt;=\", 100] }]<br />          Location : [\"New York\"]<br />        }<br />      })<br />    }<br />  }<br />}</p><br /><h3 id=\"amazon-mq-activemq\">Amazon MQ (ActiveMQ)</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  batch_size       = 10<br />  event_source_arn = aws_mq_broker.example.arn<br />  enabled          = true<br />  function_name    = aws_lambda_function.example.arn<br />  queues           = [\"example\"]</p><br /><p>source_access_configuration {<br />    type = \"BASIC_AUTH\"<br />    uri  = aws_secretsmanager_secret_version.example.arn<br />  }<br />}</p><br /><h3 id=\"amazon-mq-rabbitmq\">Amazon MQ (RabbitMQ)</h3><br /><p>terraform<br />resource \"aws_lambda_event_source_mapping\" \"example\" {<br />  batch_size       = 1<br />  event_source_arn = aws_mq_broker.example.arn<br />  enabled          = true<br />  function_name    = aws_lambda_function.example.arn<br />  queues           = [\"example\"]</p><br /><p>source_access_configuration {<br />    type = \"VIRTUAL_HOST\"<br />    uri  = \"/example\"<br />  }</p><br /><p>source_access_configuration {<br />    type = \"BASIC_AUTH\"<br />    uri  = aws_secretsmanager_secret_version.example.arn<br />  }<br />}</p><br />", "argument-reference": "<h2 id=\"argument-reference\">Argument Reference</h2><ul><li><code>amazon_managed_kafka_event_source_config</code> - (Optional) Additional configuration block for Amazon Managed Kafka sources. Incompatible with \"self_managed_event_source\" and \"self_managed_kafka_event_source_config\". Detailed below.</li><li><code>batch_size</code> - (Optional) The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to <code>100</code> for DynamoDB, Kinesis, MQ and MSK, <code>10</code> for SQS.</li><li><code>bisect_batch_on_function_error</code>: - (Optional) If the function returns an error, split the batch in two and retry. Only available for stream sources (DynamoDB and Kinesis). Defaults to <code>false</code>.</li><li><code>destination_config</code>: - (Optional) An Amazon SQS queue or Amazon SNS topic destination for failed records. Only available for stream sources (DynamoDB and Kinesis). Detailed below.</li><li><code>document_db_event_source_config</code>: - (Optional) Configuration settings for a DocumentDB event source. Detailed below.</li><li><code>enabled</code> - (Optional) Determines if the mapping will be enabled on creation. Defaults to <code>true</code>.</li><li><code>event_source_arn</code> - (Optional) The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream.  It is incompatible with a Self Managed Kafka source.</li><li><code>filter_criteria</code> - (Optional) The criteria to use for <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html\">event filtering</a> Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.</li><li><code>function_name</code> - (Required) The name or the ARN of the Lambda function that will be subscribing to events.</li><li><code>function_response_types</code> - (Optional) A list of current response type enums applied to the event source mapping for <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting\">AWS Lambda checkpointing</a>. Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: <code>ReportBatchItemFailures</code>.</li><li><code>maximum_batching_window_in_seconds</code> - (Optional) The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either <code>maximum_batching_window_in_seconds</code> expires or <code>batch_size</code> has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.</li><li><code>maximum_record_age_in_seconds</code>: - (Optional) The maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).</li><li><code>maximum_retry_attempts</code>: - (Optional) The maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.</li><li><code>parallelization_factor</code>: - (Optional) The number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.</li><li><code>queues</code> - (Optional) The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.</li><li><code>scaling_config</code> - (Optional) Scaling configuration of the event source. Only available for SQS queues. Detailed below.</li><li><code>self_managed_event_source</code>: - (Optional) For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include <code>source_access_configuration</code>. Detailed below.</li><li><code>self_managed_kafka_event_source_config</code> - (Optional) Additional configuration block for Self Managed Kafka sources. Incompatible with \"event_source_arn\" and \"amazon_managed_kafka_event_source_config\". Detailed below.</li><li><code>source_access_configuration</code>: (Optional) For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include <code>self_managed_event_source</code>. Detailed below.</li><li><code>starting_position</code> - (Optional) The position in the stream where AWS Lambda should start reading. Must be one of <code>AT_TIMESTAMP</code> (Kinesis only), <code>LATEST</code> or <code>TRIM_HORIZON</code> if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the <a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetShardIterator.html\">AWS DynamoDB Streams API Reference</a> and <a href=\"https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType\">AWS Kinesis API Reference</a>.</li><li><code>starting_position_timestamp</code> - (Optional) A timestamp in <a href=\"https://tools.ietf.org/html/rfc3339#section-5.8\">RFC3339 format</a> of the data record which to start reading when using <code>starting_position</code> set to <code>AT_TIMESTAMP</code>. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.</li><li><code>topics</code> - (Optional) The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.</li><li><code>tumbling_window_in_seconds</code> - (Optional) The duration in seconds of a processing window for <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-windows\">AWS Lambda streaming analytics</a>. The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).</li></ul><h3 id=\"amazon_managed_kafka_event_source_config-configuration-block\">amazon_managed_kafka_event_source_config Configuration Block</h3><ul><li><code>consumer_group_id</code> - (Optional) A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/API_AmazonManagedKafkaEventSourceConfig.html\">AmazonManagedKafkaEventSourceConfig Syntax</a>.</li></ul><h3 id=\"destination_config-configuration-block\">destination_config Configuration Block</h3><ul><li><code>on_failure</code> - (Optional) The destination configuration for failed invocations. Detailed below.</li></ul><h4 id=\"destination_config-on_failure-configuration-block\">destination_config on_failure Configuration Block</h4><ul><li><code>destination_arn</code> - (Required) The Amazon Resource Name (ARN) of the destination resource.</li></ul><h3 id=\"document_db_event_source_config-configuration-block\">document_db_event_source_config Configuration Block</h3><ul><li><code>collection_name</code> - (Optional) The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.</li><li><code>database_name</code> - (Required) The name of the database to consume within the DocumentDB cluster.</li><li><code>full_document</code> - (Optional) Determines what DocumentDB sends to your event stream during document update operations. If set to <code>UpdateLookup</code>, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes. Valid values: <code>UpdateLookup</code>, <code>Default</code>.</li></ul><h3 id=\"filter_criteria-configuration-block\">filter_criteria Configuration Block</h3><ul><li><code>filter</code> - (Optional) A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.</li></ul><h4 id=\"filter_criteria-filter-configuration-block\">filter_criteria filter Configuration Block</h4><ul><li><code>pattern</code> - (Optional) A filter pattern up to 4096 characters. See <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-syntax\">Filter Rule Syntax</a>.</li></ul><h3 id=\"scaling_config-configuration-block\">scaling_config Configuration Block</h3><ul><li><code>maximum_concurrency</code> - (Optional) Limits the number of concurrent instances that the Amazon SQS event source can invoke. Must be between <code>2</code> and <code>1000</code>. See <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency\">Configuring maximum concurrency for Amazon SQS event sources</a>.</li></ul><h3 id=\"self_managed_event_source-configuration-block\">self_managed_event_source Configuration Block</h3><ul><li><code>endpoints</code> - (Required) A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be <code>KAFKA_BOOTSTRAP_SERVERS</code> and the value should be a string with a comma separated list of broker endpoints.</li></ul><h3 id=\"self_managed_kafka_event_source_config-configuration-block\">self_managed_kafka_event_source_config Configuration Block</h3><ul><li><code>consumer_group_id</code> - (Optional) A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/API_SelfManagedKafkaEventSourceConfig.html\">SelfManagedKafkaEventSourceConfig Syntax</a>.</li></ul><h3 id=\"source_access_configuration-configuration-block\">source_access_configuration Configuration Block</h3><ul><li><code>type</code> - (Required) The type of this configuration.  For Self Managed Kafka you will need to supply blocks for type <code>VPC_SUBNET</code> and <code>VPC_SECURITY_GROUP</code>.</li><li><code>uri</code> - (Required) The URI for this configuration.  For type <code>VPC_SUBNET</code> the value should be <code>subnet:subnet_id</code> where <code>subnet_id</code> is the value you would find in an aws_subnet resource's id attribute.  For type <code>VPC_SECURITY_GROUP</code> the value should be <code>security_group:security_group_id</code> where <code>security_group_id</code> is the value you would find in an aws_security_group resource's id attribute.</li></ul>", "attribute-reference": "<h2 id=\"attribute-reference\">Attribute Reference</h2><p>This resource exports the following attributes in addition to the arguments above:</p><ul><li><code>function_arn</code> - The the ARN of the Lambda function the event source mapping is sending events to. (Note: this is a computed value that differs from <code>function_name</code> above.)</li><li><code>last_modified</code> - The date this resource was last modified.</li><li><code>last_processing_result</code> - The result of the last AWS Lambda invocation of your Lambda function.</li><li><code>state</code> - The state of the event source mapping.</li><li><code>state_transition_reason</code> - The reason the event source mapping is in its current state.</li><li><code>uuid</code> - The UUID of the created event source mapping.</li></ul>", "import": "<h2 id=\"import\">Import</h2><p>In Terraform v1.5.0 and later, use an <a href=\"https://developer.hashicorp.com/terraform/language/import\"><code>import</code> block</a> to import Lambda event source mappings using the <code>UUID</code> (event source mapping identifier). For example:</p><p>terraform<br />import {<br />  to = aws_lambda_event_source_mapping.event_source_mapping<br />  id = \"12345kxodurf3443\"<br />}</p><p>Using <code>terraform import</code>, import Lambda event source mappings using the <code>UUID</code> (event source mapping identifier). For example:</p><p>console<br />% terraform import aws_lambda_event_source_mapping.event_source_mapping 12345kxodurf3443</p>", "description": "<h1 id=\"resource-aws_lambda_event_source_mapping\">Resource: aws_lambda_event_source_mapping</h1><p>Provides a Lambda event source mapping. This allows Lambda functions to get events from Kinesis, DynamoDB, SQS, Amazon MQ and Managed Streaming for Apache Kafka (MSK).</p><p>For information about Lambda and how to use it, see <a href=\"http://docs.aws.amazon.com/lambda/latest/dg/welcome.html\">What is AWS Lambda?</a>.<br />For information about event source mappings, see <a href=\"http://docs.aws.amazon.com/lambda/latest/dg/API_CreateEventSourceMapping.html\">CreateEventSourceMapping</a> in the API docs.</p>"}