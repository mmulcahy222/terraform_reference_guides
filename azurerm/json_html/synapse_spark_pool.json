{"azurerm-synapse-spark-pool": "<h1 id=\"azurerm_synapse_spark_pool\">azurerm_synapse_spark_pool</h1><p>Manages a Synapse Spark Pool.</p>", "example-usage": "<h2 id=\"example-usage\">Example Usage</h2><p>resource \"azurerm_resource_group\" \"example\" {<br />  name     = \"example-resources\"<br />  location = \"West Europe\"<br />}</p><br /><p>resource \"azurerm_storage_account\" \"example\" {<br />  name                     = \"examplestorageacc\"<br />  resource_group_name      = azurerm_resource_group.example.name<br />  location                 = azurerm_resource_group.example.location<br />  account_tier             = \"Standard\"<br />  account_replication_type = \"LRS\"<br />  account_kind             = \"StorageV2\"<br />  is_hns_enabled           = \"true\"<br />}</p><br /><p>resource \"azurerm_storage_data_lake_gen2_filesystem\" \"example\" {<br />  name               = \"example\"<br />  storage_account_id = azurerm_storage_account.example.id<br />}</p><br /><p>resource \"azurerm_synapse_workspace\" \"example\" {<br />  name                                 = \"example\"<br />  resource_group_name                  = azurerm_resource_group.example.name<br />  location                             = azurerm_resource_group.example.location<br />  storage_data_lake_gen2_filesystem_id = azurerm_storage_data_lake_gen2_filesystem.example.id<br />  sql_administrator_login              = \"sqladminuser\"<br />  sql_administrator_login_password     = \"H@Sh1CoR3!\"</p><br /><p>identity {<br />    type = \"SystemAssigned\"<br />  }<br />}</p><br /><p>resource \"azurerm_synapse_spark_pool\" \"example\" {<br />  name                 = \"example\"<br />  synapse_workspace_id = azurerm_synapse_workspace.example.id<br />  node_size_family     = \"MemoryOptimized\"<br />  node_size            = \"Small\"<br />  cache_size           = 100</p><br /><p>auto_scale {<br />    max_node_count = 50<br />    min_node_count = 3<br />  }</p><br /><p>auto_pause {<br />    delay_in_minutes = 15<br />  }</p><br /><p>library_requirement {<br />    content  = &lt;&lt;EOF<br />appnope==0.1.0<br />beautifulsoup4==4.6.3<br />EOF<br />    filename = \"requirements.txt\"<br />  }</p><br /><p>spark_config {<br />    content  = &lt;&lt;EOF<br />spark.shuffle.spill                true<br />EOF<br />    filename = \"config.txt\"<br />  }</p><br /><p>tags = {<br />    ENV = \"Production\"<br />  }<br />}</p><br />", "arguments-reference": "<h2 id=\"arguments-reference\">Arguments Reference</h2><p>The following arguments are supported:</p><ul><li><p><code>name</code> - (Required) The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.</p></li><li><p><code>synapse_workspace_id</code> - (Required) The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.</p></li><li><p><code>node_size_family</code> - (Required) The kind of nodes that the Spark Pool provides. Possible values are <code>HardwareAcceleratedFPGA</code>, <code>HardwareAcceleratedGPU</code>, <code>MemoryOptimized</code>, and <code>None</code>.</p></li><li><p><code>node_size</code> - (Required) The level of node in the Spark Pool. Possible values are <code>Small</code>, <code>Medium</code>, <code>Large</code>, <code>None</code>, <code>XLarge</code>, <code>XXLarge</code> and <code>XXXLarge</code>.</p></li><li><p><code>node_count</code> - (Optional) The number of nodes in the Spark Pool. Exactly one of <code>node_count</code> or <code>auto_scale</code> must be specified.</p></li><li><p><code>auto_scale</code> - (Optional) An <code>auto_scale</code> block as defined below. Exactly one of <code>node_count</code> or <code>auto_scale</code> must be specified.</p></li><li><p><code>auto_pause</code> - (Optional) An <code>auto_pause</code> block as defined below.</p></li><li><p><code>cache_size</code> - (Optional) The cache size in the Spark Pool.</p></li><li><p><code>compute_isolation_enabled</code> - (Optional) Indicates whether compute isolation is enabled or not. Defaults to <code>false</code>.</p></li></ul><p>~&gt; <strong>NOTE:</strong> The <code>compute_isolation_enabled</code> is only available with the XXXLarge (80 vCPU / 504 GB) node size and only available in the following regions: East US, West US 2, South Central US, US Gov Arizona, US Gov Virginia. See <a href=\"https://docs.microsoft.com/azure/synapse-analytics/spark/apache-spark-pool-configurations#isolated-compute\">Isolated Compute</a> for more information.</p><ul><li><p><code>dynamic_executor_allocation_enabled</code> - (Optional) Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to <code>false</code>.</p></li><li><p><code>min_executors</code> - (Optional) The minimum number of executors allocated only when <code>dynamic_executor_allocation_enabled</code> set to <code>true</code>.</p></li><li><p><code>max_executors</code> - (Optional) The maximum number of executors allocated only when <code>dynamic_executor_allocation_enabled</code> set to <code>true</code>.</p></li><li><p><code>library_requirement</code> - (Optional) A <code>library_requirement</code> block as defined below.</p></li><li><p><code>session_level_packages_enabled</code> - (Optional) Indicates whether session level packages are enabled or not. Defaults to <code>false</code>.</p></li><li><p><code>spark_config</code> - (Optional) A <code>spark_config</code> block as defined below.</p></li><li><p><code>spark_log_folder</code> - (Optional) The default folder where Spark logs will be written. Defaults to <code>/logs</code>.</p></li><li><p><code>spark_events_folder</code> - (Optional) The Spark events folder. Defaults to <code>/events</code>.</p></li><li><p><code>spark_version</code> - (Optional) The Apache Spark version. Possible values are <code>2.4</code> , <code>3.1</code> , <code>3.2</code> and <code>3.3</code>. Defaults to <code>2.4</code>.</p></li><li><p><code>tags</code> - (Optional) A mapping of tags which should be assigned to the Synapse Spark Pool.</p></li></ul><hr /><p>An <code>auto_pause</code> block supports the following:</p><ul><li><code>delay_in_minutes</code> - (Required) Number of minutes of idle time before the Spark Pool is automatically paused. Must be between <code>5</code> and <code>10080</code>.</li></ul><hr /><p>An <code>auto_scale</code> block supports the following:</p><ul><li><p><code>max_node_count</code> - (Required) The maximum number of nodes the Spark Pool can support. Must be between <code>3</code> and <code>200</code>.</p></li><li><p><code>min_node_count</code> - (Required) The minimum number of nodes the Spark Pool can support. Must be between <code>3</code> and <code>200</code>.</p></li></ul><hr /><p>An <code>library_requirement</code> block supports the following:</p><ul><li><p><code>content</code> - (Required) The content of library requirements.</p></li><li><p><code>filename</code> - (Required) The name of the library requirements file.</p></li></ul><hr /><p>An <code>spark_config</code> block supports the following:</p><ul><li><p><code>content</code> - (Required) The contents of a spark configuration.</p></li><li><p><code>filename</code> - (Required) The name of the file where the spark configuration <code>content</code> will be stored.</p></li></ul>", "attributes-reference": "<h2 id=\"attributes-reference\">Attributes Reference</h2><p>In addition to the Arguments listed above - the following Attributes are exported:</p><ul><li><code>id</code> - The ID of the Synapse Spark Pool.</li></ul>", "timeouts": "<h2 id=\"timeouts\">Timeouts</h2><p>The <code>timeouts</code> block allows you to specify <a href=\"https://www.terraform.io/language/resources/syntax#operation-timeouts\">timeouts</a> for certain actions:</p><ul><li><code>create</code> - (Defaults to 30 minutes) Used when creating the Synapse Spark Pool.</li><li><code>read</code> - (Defaults to 5 minutes) Used when retrieving the Synapse Spark Pool.</li><li><code>update</code> - (Defaults to 30 minutes) Used when updating the Synapse Spark Pool.</li><li><code>delete</code> - (Defaults to 30 minutes) Used when deleting the Synapse Spark Pool.</li></ul>", "import": "<h2 id=\"import\">Import</h2><p>Synapse Spark Pool can be imported using the <code>resource id</code>, e.g.</p><p>shell<br />terraform import azurerm_synapse_spark_pool.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.Synapse/workspaces/workspace1/bigDataPools/sparkPool1</p>", "description": "<h1 id=\"azurerm_synapse_spark_pool\">azurerm_synapse_spark_pool</h1><p>Manages a Synapse Spark Pool.</p>"}