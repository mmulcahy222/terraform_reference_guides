{"azurerm-kubernetes-cluster-node-pool": "<h1 id=\"azurerm_kubernetes_cluster_node_pool\">azurerm_kubernetes_cluster_node_pool</h1><p>Manages a Node Pool within a Kubernetes Cluster</p><p>-&gt; <strong>Note:</strong> Due to the fast-moving nature of AKS, we recommend using the latest version of the Azure Provider when using AKS - you can find <a href=\"https://registry.terraform.io/providers/hashicorp/azurerm/latest\">the latest version of the Azure Provider here</a>.</p><p>~&gt; <strong>NOTE:</strong> Multiple Node Pools are only supported when the Kubernetes Cluster is using Virtual Machine Scale Sets.</p>", "example-usage": "<h2 id=\"example-usage\">Example Usage</h2><p>This example provisions a basic Kubernetes Node Pool. Other examples of the <code>azurerm_kubernetes_cluster_node_pool</code> resource can be found in <a href=\"https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples/kubernetes\">the <code>./examples/kubernetes</code> directory within the GitHub Repository</a></p><br /><p>resource \"azurerm_resource_group\" \"example\" {<br />  name     = \"example-resources\"<br />  location = \"West Europe\"<br />}</p><br /><p>resource \"azurerm_kubernetes_cluster\" \"example\" {<br />  name                = \"example-aks1\"<br />  location            = azurerm_resource_group.example.location<br />  resource_group_name = azurerm_resource_group.example.name<br />  dns_prefix          = \"exampleaks1\"</p><br /><p>default_node_pool {<br />    name       = \"default\"<br />    node_count = 1<br />    vm_size    = \"Standard_D2_v2\"<br />  }</p><br /><p>service_principal {<br />    client_id     = \"00000000-0000-0000-0000-000000000000\"<br />    client_secret = \"00000000000000000000000000000000\"<br />  }<br />}</p><br /><p>resource \"azurerm_kubernetes_cluster_node_pool\" \"example\" {<br />  name                  = \"internal\"<br />  kubernetes_cluster_id = azurerm_kubernetes_cluster.example.id<br />  vm_size               = \"Standard_DS2_v2\"<br />  node_count            = 1</p><br /><p>tags = {<br />    Environment = \"Production\"<br />  }<br />}</p><br />", "argument-reference": "<h2 id=\"argument-reference\">Argument Reference</h2><p>The following arguments are supported:</p><ul><li><code>name</code> - (Required) The name of the Node Pool which should be created within the Kubernetes Cluster. Changing this forces a new resource to be created.</li></ul><p>~&gt; <strong>NOTE:</strong> A Windows Node Pool cannot have a <code>name</code> longer than 6 characters.</p><ul><li><code>kubernetes_cluster_id</code> - (Required) The ID of the Kubernetes Cluster where this Node Pool should exist. Changing this forces a new resource to be created.</li></ul><p>~&gt; <strong>NOTE:</strong> The type of Default Node Pool for the Kubernetes Cluster must be <code>VirtualMachineScaleSets</code> to attach multiple node pools.</p><ul><li><code>vm_size</code> - (Required) The SKU which should be used for the Virtual Machines used in this Node Pool. Changing this forces a new resource to be created.</li></ul><hr /><ul><li><p><code>capacity_reservation_group_id</code> - (Optional) Specifies the ID of the Capacity Reservation Group where this Node Pool should exist. Changing this forces a new resource to be created.</p></li><li><p><code>custom_ca_trust_enabled</code> - (Optional) Specifies whether to trust a Custom CA.</p></li></ul><p>-&gt; <strong>Note:</strong> This requires that the Preview Feature <code>Microsoft.ContainerService/CustomCATrustPreview</code> is enabled and the Resource Provider is re-registered, see <a href=\"https://learn.microsoft.com/en-us/azure/aks/custom-certificate-authority\">the documentation</a> for more information.</p><ul><li><p><code>enable_auto_scaling</code> - (Optional) Whether to enable <a href=\"https://docs.microsoft.com/azure/aks/cluster-autoscaler\">auto-scaler</a>.</p></li><li><p><code>enable_host_encryption</code> - (Optional) Should the nodes in this Node Pool have host encryption enabled? Changing this forces a new resource to be created.</p></li></ul><p>~&gt; <strong>NOTE:</strong> Additional fields must be configured depending on the value of this field - see below.</p><ul><li><p><code>enable_node_public_ip</code> - (Optional) Should each node have a Public IP Address? Changing this forces a new resource to be created.</p></li><li><p><code>eviction_policy</code> - (Optional) The Eviction Policy which should be used for Virtual Machines within the Virtual Machine Scale Set powering this Node Pool. Possible values are <code>Deallocate</code> and <code>Delete</code>. Changing this forces a new resource to be created.</p></li></ul><p>~&gt; <strong>Note:</strong> An Eviction Policy can only be configured when <code>priority</code> is set to <code>Spot</code> and will default to <code>Delete</code> unless otherwise specified.</p><ul><li><p><code>host_group_id</code> - (Optional) The fully qualified resource ID of the Dedicated Host Group to provision virtual machines from. Changing this forces a new resource to be created.</p></li><li><p><code>kubelet_config</code> - (Optional) A <code>kubelet_config</code> block as defined below. Changing this forces a new resource to be created.</p></li><li><p><code>linux_os_config</code> - (Optional) A <code>linux_os_config</code> block as defined below. Changing this forces a new resource to be created.</p></li><li><p><code>fips_enabled</code> - (Optional) Should the nodes in this Node Pool have Federal Information Processing Standard enabled? Changing this forces a new resource to be created.</p></li></ul><p>~&gt; <strong>Note:</strong> FIPS support is in Public Preview - more information and details on how to opt into the Preview can be found in <a href=\"https://docs.microsoft.com/azure/aks/use-multiple-node-pools#add-a-fips-enabled-node-pool-preview\">this article</a>.</p><ul><li><p><code>kubelet_disk_type</code> - (Optional) The type of disk used by kubelet. Possible values are <code>OS</code> and <code>Temporary</code>.</p></li><li><p><code>max_pods</code> - (Optional) The maximum number of pods that can run on each agent. Changing this forces a new resource to be created.</p></li><li><p><code>message_of_the_day</code> - (Optional) A base64-encoded string which will be written to /etc/motd after decoding. This allows customization of the message of the day for Linux nodes. It cannot be specified for Windows nodes and must be a static string (i.e. will be printed raw and not executed as a script). Changing this forces a new resource to be created.</p></li><li><p><code>mode</code> - (Optional) Should this Node Pool be used for System or User resources? Possible values are <code>System</code> and <code>User</code>. Defaults to <code>User</code>.</p></li><li><p><code>node_network_profile</code> - (Optional) A <code>node_network_profile</code> block as documented below.</p></li><li><p><code>node_labels</code> - (Optional) A map of Kubernetes labels which should be applied to nodes in this Node Pool.</p></li><li><p><code>node_public_ip_prefix_id</code> - (Optional) Resource ID for the Public IP Addresses Prefix for the nodes in this Node Pool. <code>enable_node_public_ip</code> should be <code>true</code>. Changing this forces a new resource to be created.</p></li><li><p><code>node_taints</code> - (Optional) A list of Kubernetes taints which should be applied to nodes in the agent pool (e.g <code>key=value:NoSchedule</code>). Changing this forces a new resource to be created.</p></li><li><p><code>orchestrator_version</code> - (Optional) Version of Kubernetes used for the Agents. If not specified, the latest recommended version will be used at provisioning time (but won't auto-upgrade). AKS does not require an exact patch version to be specified, minor version aliases such as <code>1.22</code> are also supported. - The minor version's latest GA patch is automatically chosen in that case. More details can be found in <a href=\"https://docs.microsoft.com/en-us/azure/aks/supported-kubernetes-versions?tabs=azure-cli#alias-minor-version\">the documentation</a>.</p></li></ul><p>-&gt; <strong>Note:</strong> This version must be supported by the Kubernetes Cluster - as such the version of Kubernetes used on the Cluster/Control Plane may need to be upgraded first.</p><ul><li><p><code>os_disk_size_gb</code> - (Optional) The Agent Operating System disk size in GB. Changing this forces a new resource to be created.</p></li><li><p><code>os_disk_type</code> - (Optional) The type of disk which should be used for the Operating System. Possible values are <code>Ephemeral</code> and <code>Managed</code>. Defaults to <code>Managed</code>. Changing this forces a new resource to be created.</p></li><li><p><code>pod_subnet_id</code> - (Optional) The ID of the Subnet where the pods in the Node Pool should exist. Changing this forces a new resource to be created.</p></li><li><p><code>os_sku</code> - (Optional) Specifies the OS SKU used by the agent pool. Possible values include: <code>AzureLinux</code>, <code>Ubuntu</code>, <code>Windows2019</code>, <code>Windows2022</code>. If not specified, the default is <code>Ubuntu</code> if OSType=Linux or <code>Windows2019</code> if OSType=Windows. And the default Windows OSSKU will be changed to <code>Windows2022</code> after Windows2019 is deprecated. Changing this forces a new resource to be created.</p></li><li><p><code>os_type</code> - (Optional) The Operating System which should be used for this Node Pool. Changing this forces a new resource to be created. Possible values are <code>Linux</code> and <code>Windows</code>. Defaults to <code>Linux</code>.</p></li><li><p><code>priority</code> - (Optional) The Priority for Virtual Machines within the Virtual Machine Scale Set that powers this Node Pool. Possible values are <code>Regular</code> and <code>Spot</code>. Defaults to <code>Regular</code>. Changing this forces a new resource to be created.</p></li><li><p><code>proximity_placement_group_id</code> - (Optional) The ID of the Proximity Placement Group where the Virtual Machine Scale Set that powers this Node Pool will be placed. Changing this forces a new resource to be created.</p></li></ul><p>-&gt; <strong>Note:</strong> When setting <code>priority</code> to Spot - you must configure an <code>eviction_policy</code>, <code>spot_max_price</code> and add the applicable <code>node_labels</code> and <code>node_taints</code> <a href=\"https://docs.microsoft.com/azure/aks/spot-node-pool\">as per the Azure Documentation</a>.</p><ul><li><code>spot_max_price</code> - (Optional) The maximum price you're willing to pay in USD per Virtual Machine. Valid values are <code>-1</code> (the current on-demand price for a Virtual Machine) or a positive value with up to five decimal places. Changing this forces a new resource to be created.</li></ul><p>~&gt; <strong>Note:</strong> This field can only be configured when <code>priority</code> is set to <code>Spot</code>.</p><ul><li><p><code>snapshot_id</code> - (Optional) The ID of the Snapshot which should be used to create this Node Pool. Changing this forces a new resource to be created.</p></li><li><p><code>tags</code> - (Optional) A mapping of tags to assign to the resource.</p></li></ul><p>~&gt; At this time there's a bug in the AKS API where Tags for a Node Pool are not stored in the correct case - you <a href=\"https://www.terraform.io/language/meta-arguments/lifecycle#ignore_changess\">may wish to use Terraform's <code>ignore_changes</code> functionality to ignore changes to the casing</a> until this is fixed in the AKS API.</p><ul><li><p><code>scale_down_mode</code> - (Optional) Specifies how the node pool should deal with scaled-down nodes. Allowed values are <code>Delete</code> and <code>Deallocate</code>. Defaults to <code>Delete</code>.</p></li><li><p><code>ultra_ssd_enabled</code> - (Optional) Used to specify whether the UltraSSD is enabled in the Node Pool. Defaults to <code>false</code>. See <a href=\"https://docs.microsoft.com/azure/aks/use-ultra-disks\">the documentation</a> for more information. Changing this forces a new resource to be created.</p></li><li><p><code>upgrade_settings</code> - (Optional) A <code>upgrade_settings</code> block as documented below.</p></li><li><p><code>vnet_subnet_id</code> - (Optional) The ID of the Subnet where this Node Pool should exist. Changing this forces a new resource to be created.</p></li></ul><p>~&gt; <strong>NOTE:</strong> A route table must be configured on this Subnet.</p><ul><li><p><code>windows_profile</code> - (Optional) A <code>windows_profile</code> block as documented below. Changing this forces a new resource to be created.</p></li><li><p><code>workload_runtime</code> - (Optional) Used to specify the workload runtime. Allowed values are <code>OCIContainer</code>, <code>WasmWasi</code> and <code>KataMshvVmIsolation</code>.</p></li></ul><p>~&gt; <strong>Note:</strong> WebAssembly System Interface node pools are in Public Preview - more information and details on how to opt into the preview can be found in <a href=\"https://docs.microsoft.com/azure/aks/use-wasi-node-pools\">this article</a></p><p>~&gt; <strong>Note:</strong> Pod Sandboxing / KataVM Isolation node pools are in Public Preview - more information and details on how to opt into the preview can be found in <a href=\"https://learn.microsoft.com/azure/aks/use-pod-sandboxing\">this article</a></p><ul><li><code>zones</code> - (Optional) Specifies a list of Availability Zones in which this Kubernetes Cluster Node Pool should be located. Changing this forces a new Kubernetes Cluster Node Pool to be created.</li></ul><hr /><p>If <code>enable_auto_scaling</code> is set to <code>true</code>, then the following fields can also be configured:</p><ul><li><p><code>max_count</code> - (Optional) The maximum number of nodes which should exist within this Node Pool. Valid values are between <code>0</code> and <code>1000</code> and must be greater than or equal to <code>min_count</code>.</p></li><li><p><code>min_count</code> - (Optional) The minimum number of nodes which should exist within this Node Pool. Valid values are between <code>0</code> and <code>1000</code> and must be less than or equal to <code>max_count</code>.</p></li><li><p><code>node_count</code> - (Optional) The initial number of nodes which should exist within this Node Pool. Valid values are between <code>0</code> and <code>1000</code> (inclusive) for user pools and between <code>1</code> and <code>1000</code> (inclusive) for system pools and must be a value in the range <code>min_count</code> - <code>max_count</code>.</p></li></ul><p>-&gt; <strong>NOTE:</strong> If you're specifying an initial number of nodes you may wish to use <a href=\"https://www.terraform.io/language/meta-arguments/lifecycle#ignore_changess\">Terraform's <code>ignore_changes</code> functionality</a> to ignore changes to this field.</p><p>If <code>enable_auto_scaling</code> is set to <code>false</code>, then the following fields can also be configured:</p><ul><li><code>node_count</code> - (Optional) The number of nodes which should exist within this Node Pool. Valid values are between <code>0</code> and <code>1000</code> (inclusive) for user pools and between <code>1</code> and <code>1000</code> (inclusive) for system pools.</li></ul><hr /><p>A <code>kubelet_config</code> block supports the following:</p><ul><li><p><code>allowed_unsafe_sysctls</code> - (Optional) Specifies the allow list of unsafe sysctls command or patterns (ending in <code>*</code>). Changing this forces a new resource to be created.</p></li><li><p><code>container_log_max_line</code> - (Optional) Specifies the maximum number of container log files that can be present for a container. must be at least 2. Changing this forces a new resource to be created.</p></li><li><p><code>container_log_max_size_mb</code> - (Optional) Specifies the maximum size (e.g. 10MB) of container log file before it is rotated. Changing this forces a new resource to be created.</p></li><li><p><code>cpu_cfs_quota_enabled</code> - (Optional) Is CPU CFS quota enforcement for containers enabled? Changing this forces a new resource to be created.</p></li><li><p><code>cpu_cfs_quota_period</code> - (Optional) Specifies the CPU CFS quota period value. Changing this forces a new resource to be created.</p></li><li><p><code>cpu_manager_policy</code> - (Optional) Specifies the CPU Manager policy to use. Possible values are <code>none</code> and <code>static</code>, Changing this forces a new resource to be created.</p></li><li><p><code>image_gc_high_threshold</code> - (Optional) Specifies the percent of disk usage above which image garbage collection is always run. Must be between <code>0</code> and <code>100</code>. Changing this forces a new resource to be created.</p></li><li><p><code>image_gc_low_threshold</code> - (Optional) Specifies the percent of disk usage lower than which image garbage collection is never run. Must be between <code>0</code> and <code>100</code>. Changing this forces a new resource to be created.</p></li><li><p><code>pod_max_pid</code> - (Optional) Specifies the maximum number of processes per pod. Changing this forces a new resource to be created.</p></li><li><p><code>topology_manager_policy</code> - (Optional) Specifies the Topology Manager policy to use. Possible values are <code>none</code>, <code>best-effort</code>, <code>restricted</code> or <code>single-numa-node</code>. Changing this forces a new resource to be created.</p></li></ul><hr /><p>A <code>linux_os_config</code> block supports the following:</p><ul><li><p><code>swap_file_size_mb</code> - (Optional) Specifies the size of swap file on each node in MB. Changing this forces a new resource to be created.</p></li><li><p><code>sysctl_config</code> - (Optional) A <code>sysctl_config</code> block as defined below. Changing this forces a new resource to be created.</p></li><li><p><code>transparent_huge_page_defrag</code> - (Optional) specifies the defrag configuration for Transparent Huge Page. Possible values are <code>always</code>, <code>defer</code>, <code>defer+madvise</code>, <code>madvise</code> and <code>never</code>. Changing this forces a new resource to be created.</p></li><li><p><code>transparent_huge_page_enabled</code> - (Optional) Specifies the Transparent Huge Page enabled configuration. Possible values are <code>always</code>, <code>madvise</code> and <code>never</code>. Changing this forces a new resource to be created.</p></li></ul><hr /><p>A <code>node_network_profile</code> block supports the following:</p><ul><li><code>node_public_ip_tags</code> - (Optional) Specifies a mapping of tags to the instance-level public IPs. Changing this forces a new resource to be created.</li></ul><p>-&gt; <strong>Note:</strong> This requires that the Preview Feature <code>Microsoft.ContainerService/NodePublicIPTagsPreview</code> is enabled and the Resource Provider is re-registered, see <a href=\"https://learn.microsoft.com/azure/aks/use-node-public-ips#use-public-ip-tags-on-node-public-ips-preview\">the documentation</a> for more information.</p><hr /><p>A <code>sysctl_config</code> block supports the following:</p><p>~&gt; For more information, please refer to <a href=\"https://www.kernel.org/doc/html/latest/admin-guide/sysctl/index.html\">Linux Kernel Doc</a>.</p><ul><li><p><code>fs_aio_max_nr</code> - (Optional) The sysctl setting fs.aio-max-nr. Must be between <code>65536</code> and <code>6553500</code>. Changing this forces a new resource to be created.</p></li><li><p><code>fs_file_max</code> - (Optional) The sysctl setting fs.file-max. Must be between <code>8192</code> and <code>12000500</code>. Changing this forces a new resource to be created.</p></li><li><p><code>fs_inotify_max_user_watches</code> - (Optional) The sysctl setting fs.inotify.max_user_watches. Must be between <code>781250</code> and <code>2097152</code>. Changing this forces a new resource to be created.</p></li><li><p><code>fs_nr_open</code> - (Optional) The sysctl setting fs.nr_open. Must be between <code>8192</code> and <code>20000500</code>. Changing this forces a new resource to be created.</p></li><li><p><code>kernel_threads_max</code> - (Optional) The sysctl setting kernel.threads-max. Must be between <code>20</code> and <code>513785</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_netdev_max_backlog</code> - (Optional) The sysctl setting net.core.netdev_max_backlog. Must be between <code>1000</code> and <code>3240000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_optmem_max</code> - (Optional) The sysctl setting net.core.optmem_max. Must be between <code>20480</code> and <code>4194304</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_rmem_default</code> - (Optional) The sysctl setting net.core.rmem_default. Must be between <code>212992</code> and <code>134217728</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_rmem_max</code> - (Optional) The sysctl setting net.core.rmem_max. Must be between <code>212992</code> and <code>134217728</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_somaxconn</code> - (Optional) The sysctl setting net.core.somaxconn. Must be between <code>4096</code> and <code>3240000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_wmem_default</code> - (Optional) The sysctl setting net.core.wmem_default. Must be between <code>212992</code> and <code>134217728</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_core_wmem_max</code> - (Optional) The sysctl setting net.core.wmem_max. Must be between <code>212992</code> and <code>134217728</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_ip_local_port_range_max</code> - (Optional) The sysctl setting net.ipv4.ip_local_port_range max value. Must be between <code>32768</code> and <code>65535</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_ip_local_port_range_min</code> - (Optional) The sysctl setting net.ipv4.ip_local_port_range min value. Must be between <code>1024</code> and <code>60999</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_neigh_default_gc_thresh1</code> - (Optional) The sysctl setting net.ipv4.neigh.default.gc_thresh1. Must be between <code>128</code> and <code>80000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_neigh_default_gc_thresh2</code> - (Optional) The sysctl setting net.ipv4.neigh.default.gc_thresh2. Must be between <code>512</code> and <code>90000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_neigh_default_gc_thresh3</code> - (Optional) The sysctl setting net.ipv4.neigh.default.gc_thresh3. Must be between <code>1024</code> and <code>100000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_fin_timeout</code> - (Optional) The sysctl setting net.ipv4.tcp_fin_timeout. Must be between <code>5</code> and <code>120</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_keepalive_intvl</code> - (Optional) The sysctl setting net.ipv4.tcp_keepalive_intvl. Must be between <code>10</code> and <code>90</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_keepalive_probes</code> - (Optional) The sysctl setting net.ipv4.tcp_keepalive_probes. Must be between <code>1</code> and <code>15</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_keepalive_time</code> - (Optional) The sysctl setting net.ipv4.tcp_keepalive_time. Must be between <code>30</code> and <code>432000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_max_syn_backlog</code> - (Optional) The sysctl setting net.ipv4.tcp_max_syn_backlog. Must be between <code>128</code> and <code>3240000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_max_tw_buckets</code> - (Optional) The sysctl setting net.ipv4.tcp_max_tw_buckets. Must be between <code>8000</code> and <code>1440000</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_ipv4_tcp_tw_reuse</code> - (Optional) Is sysctl setting net.ipv4.tcp_tw_reuse enabled? Changing this forces a new resource to be created.</p></li><li><p><code>net_netfilter_nf_conntrack_buckets</code> - (Optional) The sysctl setting net.netfilter.nf_conntrack_buckets. Must be between <code>65536</code> and <code>524288</code>. Changing this forces a new resource to be created.</p></li><li><p><code>net_netfilter_nf_conntrack_max</code> - (Optional) The sysctl setting net.netfilter.nf_conntrack_max. Must be between <code>131072</code> and <code>2097152</code>. Changing this forces a new resource to be created.</p></li><li><p><code>vm_max_map_count</code> - (Optional) The sysctl setting vm.max_map_count. Must be between <code>65530</code> and <code>262144</code>. Changing this forces a new resource to be created.</p></li><li><p><code>vm_swappiness</code> - (Optional) The sysctl setting vm.swappiness. Must be between <code>0</code> and <code>100</code>. Changing this forces a new resource to be created.</p></li><li><p><code>vm_vfs_cache_pressure</code> - (Optional) The sysctl setting vm.vfs_cache_pressure. Must be between <code>0</code> and <code>100</code>. Changing this forces a new resource to be created.</p></li></ul><hr /><p>A <code>upgrade_settings</code> block supports the following:</p><ul><li><code>max_surge</code> - (Required) The maximum number or percentage of nodes which will be added to the Node Pool size during an upgrade.</li></ul><hr /><p>A <code>windows_profile</code> block supports the following:</p><ul><li><code>outbound_nat_enabled</code> - (Optional) Should the Windows nodes in this Node Pool have outbound NAT enabled? Defaults to <code>true</code>. Changing this forces a new resource to be created.</li></ul><p>-&gt; <strong>Note:</strong> If a percentage is provided, the number of surge nodes is calculated from the current node count on the cluster. Node surge can allow a cluster to have more nodes than <code>max_count</code> during an upgrade. Ensure that your cluster has enough <a href=\"https://docs.microsoft.com/azure/aks/upgrade-cluster#customize-node-surge-upgrade\">IP space</a> during an upgrade.</p>", "attributes-reference": "<h2 id=\"attributes-reference\">Attributes Reference</h2><p>In addition to the Arguments listed above - the following Attributes are exported:</p><ul><li><code>id</code> - The ID of the Kubernetes Cluster Node Pool.</li></ul>", "timeouts": "<h2 id=\"timeouts\">Timeouts</h2><p>The <code>timeouts</code> block allows you to specify <a href=\"https://www.terraform.io/language/resources/syntax#operation-timeouts\">timeouts</a> for certain actions:</p><ul><li><code>create</code> - (Defaults to 60 minutes) Used when creating the Kubernetes Cluster Node Pool.</li><li><code>update</code> - (Defaults to 60 minutes) Used when updating the Kubernetes Cluster Node Pool.</li><li><code>read</code> - (Defaults to 5 minutes) Used when retrieving the Kubernetes Cluster Node Pool.</li><li><code>delete</code> - (Defaults to 60 minutes) Used when deleting the Kubernetes Cluster Node Pool.</li></ul>", "import": "<h2 id=\"import\">Import</h2><p>Kubernetes Cluster Node Pools can be imported using the <code>resource id</code>, e.g.</p><p>shell<br />terraform import azurerm_kubernetes_cluster_node_pool.pool1 /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.ContainerService/managedClusters/cluster1/agentPools/pool1</p>", "description": "<h1 id=\"azurerm_kubernetes_cluster_node_pool\">azurerm_kubernetes_cluster_node_pool</h1><p>Manages a Node Pool within a Kubernetes Cluster</p><p>-&gt; <strong>Note:</strong> Due to the fast-moving nature of AKS, we recommend using the latest version of the Azure Provider when using AKS - you can find <a href=\"https://registry.terraform.io/providers/hashicorp/azurerm/latest\">the latest version of the Azure Provider here</a>.</p><p>~&gt; <strong>NOTE:</strong> Multiple Node Pools are only supported when the Kubernetes Cluster is using Virtual Machine Scale Sets.</p>"}