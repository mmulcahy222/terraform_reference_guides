{"azurerm-data-factory-data-flow": "<h1 id=\"azurerm_data_factory_data_flow\">azurerm_data_factory_data_flow</h1><p>Manages a Data Flow inside an Azure Data Factory.</p>", "example-usage": "<h2 id=\"example-usage\">Example Usage</h2><p><br />resource \"azurerm_resource_group\" \"example\" {<br />  name     = \"example-resources\"<br />  location = \"West Europe\"<br />}</p><p>resource \"azurerm_storage_account\" \"example\" {<br />  name                     = \"example\"<br />  location                 = azurerm_resource_group.example.location<br />  resource_group_name      = azurerm_resource_group.example.name<br />  account_tier             = \"Standard\"<br />  account_replication_type = \"LRS\"<br />}</p><p>resource \"azurerm_data_factory\" \"example\" {<br />  name                = \"example\"<br />  location            = azurerm_resource_group.example.location<br />  resource_group_name = azurerm_resource_group.example.name<br />}</p><p>resource \"azurerm_data_factory_linked_custom_service\" \"example\" {<br />  name                 = \"linked_service\"<br />  data_factory_id      = azurerm_data_factory.example.id<br />  type                 = \"AzureBlobStorage\"<br />  type_properties_json = &lt;&lt;JSON<br />{<br />  \"connectionString\": \"${azurerm_storage_account.example.primary_connection_string}\"<br />}<br />JSON<br />}</p><p>resource \"azurerm_data_factory_dataset_json\" \"example1\" {<br />  name                = \"dataset1\"<br />  data_factory_id     = azurerm_data_factory.example.id<br />  linked_service_name = azurerm_data_factory_linked_custom_service.example.name</p><p>azure_blob_storage_location {<br />    container = \"container\"<br />    path      = \"foo/bar/\"<br />    filename  = \"foo.txt\"<br />  }</p><p>encoding = \"UTF-8\"<br />}</p><p>resource \"azurerm_data_factory_dataset_json\" \"example2\" {<br />  name                = \"dataset2\"<br />  data_factory_id     = azurerm_data_factory.example.id<br />  linked_service_name = azurerm_data_factory_linked_custom_service.example.name</p><p>azure_blob_storage_location {<br />    container = \"container\"<br />    path      = \"foo/bar/\"<br />    filename  = \"bar.txt\"<br />  }</p><p>encoding = \"UTF-8\"<br />}</p><p>resource \"azurerm_data_factory_data_flow\" \"example\" {<br />  name            = \"example\"<br />  data_factory_id = azurerm_data_factory.example.id</p><p>source {<br />    name = \"source1\"</p><pre><code>flowlet {  name = azurerm_data_factory_flowlet_data_flow.example1.name  parameters = {    \"Key1\" = \"value1\"  }}dataset {  name = azurerm_data_factory_dataset_json.example1.name}</code></pre><p>}</p><p>sink {<br />    name = \"sink1\"</p><pre><code>flowlet {  name = azurerm_data_factory_flowlet_data_flow.example2.name  parameters = {    \"Key1\" = \"value1\"  }}dataset {  name = azurerm_data_factory_dataset_json.example2.name}</code></pre><p>}</p><p>script = &lt;<EOTsource(  allowSchemaDrift: true,   validateSchema: false,   limit: 100,   ignoreNoFilesFound: false,   documentForm: 'documentPerLine') ~> source1 <br />source1 sink(<br />  allowSchemaDrift: true, <br />  validateSchema: false, <br />  skipDuplicateMapInputs: true, <br />  skipDuplicateMapOutputs: true) ~&gt; sink1<br />EOT<br />}</p><p>resource \"azurerm_data_factory_flowlet_data_flow\" \"example1\" {<br />  name            = \"example\"<br />  data_factory_id = azurerm_data_factory.example.id</p><p>source {<br />    name = \"source1\"</p><pre><code>linked_service {  name = azurerm_data_factory_linked_custom_service.example.name}</code></pre><p>}</p><p>sink {<br />    name = \"sink1\"</p><pre><code>linked_service {  name = azurerm_data_factory_linked_custom_service.example.name}</code></pre><p>}</p><p>script = &lt;<EOTsource(  allowSchemaDrift: true,   validateSchema: false,   limit: 100,   ignoreNoFilesFound: false,   documentForm: 'documentPerLine') ~> source1 <br />source1 sink(<br />  allowSchemaDrift: true, <br />  validateSchema: false, <br />  skipDuplicateMapInputs: true, <br />  skipDuplicateMapOutputs: true) ~&gt; sink1<br />EOT<br />}</p><p>resource \"azurerm_data_factory_flowlet_data_flow\" \"example2\" {<br />  name            = \"example\"<br />  data_factory_id = azurerm_data_factory.example.id</p><p>source {<br />    name = \"source1\"</p><pre><code>linked_service {  name = azurerm_data_factory_linked_custom_service.example.name}</code></pre><p>}</p><p>sink {<br />    name = \"sink1\"</p><pre><code>linked_service {  name = azurerm_data_factory_linked_custom_service.example.name}</code></pre><p>}</p><p>script = &lt;<EOTsource(  allowSchemaDrift: true,   validateSchema: false,   limit: 100,   ignoreNoFilesFound: false,   documentForm: 'documentPerLine') ~> source1 <br />source1 sink(<br />  allowSchemaDrift: true, <br />  validateSchema: false, <br />  skipDuplicateMapInputs: true, <br />  skipDuplicateMapOutputs: true) ~&gt; sink1<br />EOT<br />}<br /></p>", "argument-reference": "<h2 id=\"argument-reference\">Argument Reference</h2><p>The following arguments are supported:</p><ul><li><p><code>name</code> - (Required) Specifies the name of the Data Factory Data Flow. Changing this forces a new resource to be created.</p></li><li><p><code>data_factory_id</code> - (Required) The ID of Data Factory in which to associate the Data Flow with. Changing this forces a new resource.</p></li><li><p><code>script</code> - (Optional) The script for the Data Factory Data Flow.</p></li><li><p><code>script_lines</code> - (Optional) The script lines for the Data Factory Data Flow.</p></li><li><p><code>source</code> - (Required) One or more <code>source</code> blocks as defined below.</p></li><li><p><code>sink</code> - (Required) One or more <code>sink</code> blocks as defined below.</p></li><li><p><code>annotations</code> - (Optional) List of tags that can be used for describing the Data Factory Data Flow.</p></li><li><p><code>description</code> - (Optional) The description for the Data Factory Data Flow.</p></li><li><p><code>folder</code> - (Optional) The folder that this Data Flow is in. If not specified, the Data Flow will appear at the root level.</p></li><li><p><code>transformation</code> - (Optional) One or more <code>transformation</code> blocks as defined below.</p></li></ul><hr /><p>A <code>source</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Flow Source.</p></li><li><p><code>description</code> - (Optional) The description for the Data Flow Source.</p></li><li><p><code>dataset</code> - (Optional) A <code>dataset</code> block as defined below.</p></li><li><p><code>flowlet</code> - (Optional) A <code>flowlet</code> block as defined below.</p></li><li><p><code>linked_service</code> - (Optional) A <code>linked_service</code> block as defined below.</p></li><li><p><code>rejected_linked_service</code> - (Optional) A <code>rejected_linked_service</code> block as defined below.</p></li><li><p><code>schema_linked_service</code> - (Optional) A <code>schema_linked_service</code> block as defined below.</p></li></ul><hr /><p>A <code>sink</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Flow Source.</p></li><li><p><code>description</code> - (Optional) The description for the Data Flow Source.</p></li><li><p><code>dataset</code> - (Optional) A <code>dataset</code> block as defined below.</p></li><li><p><code>flowlet</code> - (Optional) A <code>flowlet</code> block as defined below.</p></li><li><p><code>linked_service</code> - (Optional) A <code>linked_service</code> block as defined below.</p></li><li><p><code>rejected_linked_service</code> - (Optional) A <code>rejected_linked_service</code> block as defined below.</p></li><li><p><code>schema_linked_service</code> - (Optional) A <code>schema_linked_service</code> block as defined below.</p></li></ul><hr /><p>A <code>dataset</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Factory Dataset.</p></li><li><p><code>parameters</code> - (Optional) A map of parameters to associate with the Data Factory dataset.</p></li></ul><hr /><p>A <code>flowlet</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Factory Flowlet.</p></li><li><p><code>dataset_parameters</code> - (Optional) Specifies the reference data flow parameters from dataset.</p></li><li><p><code>parameters</code> - (Optional) A map of parameters to associate with the Data Factory Flowlet.</p></li></ul><hr /><p>A <code>linked_service</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Factory Linked Service.</p></li><li><p><code>parameters</code> - (Optional) A map of parameters to associate with the Data Factory Linked Service.</p></li></ul><hr /><p>A <code>rejected_linked_service</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Factory Linked Service with schema.</p></li><li><p><code>parameters</code> - (Optional) A map of parameters to associate with the Data Factory Linked Service.</p></li></ul><hr /><p>A <code>schema_linked_service</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Factory Linked Service with schema.</p></li><li><p><code>parameters</code> - (Optional) A map of parameters to associate with the Data Factory Linked Service.</p></li></ul><hr /><p>A <code>transformation</code> block supports the following:</p><ul><li><p><code>name</code> - (Required) The name for the Data Flow transformation.</p></li><li><p><code>description</code> - (Optional) The description for the Data Flow transformation.</p></li><li><p><code>dataset</code> - (Optional) A <code>dataset</code> block as defined below.</p></li><li><p><code>flowlet</code> - (Optional) A <code>flowlet</code> block as defined below.</p></li><li><p><code>linked_service</code> - (Optional) A <code>linked_service</code> block as defined below.</p></li></ul>", "attributes-reference": "<h2 id=\"attributes-reference\">Attributes Reference</h2><p>In addition to the Arguments listed above - the following Attributes are exported:</p><ul><li><code>id</code> - The ID of the Data Factory Data Flow.</li></ul>", "timeouts": "<h2 id=\"timeouts\">Timeouts</h2><p>The <code>timeouts</code> block allows you to specify <a href=\"https://www.terraform.io/language/resources/syntax#operation-timeouts\">timeouts</a> for certain actions:</p><ul><li><code>create</code> - (Defaults to 30 minutes) Used when creating the Data Factory Data Flow.</li><li><code>update</code> - (Defaults to 30 minutes) Used when updating the Data Factory Data Flow.</li><li><code>read</code> - (Defaults to 5 minutes) Used when retrieving the Data Factory Data Flow.</li><li><code>delete</code> - (Defaults to 30 minutes) Used when deleting the Data Factory Data Flow.</li></ul>", "import": "<h2 id=\"import\">Import</h2><p>Data Factory Data Flow can be imported using the <code>resource id</code>, e.g.</p><p><code>shellterraform import azurerm_data_factory_data_flow.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/example/providers/Microsoft.DataFactory/factories/example/dataflows/example</code></p>", "description": "<h1 id=\"azurerm_data_factory_data_flow\">azurerm_data_factory_data_flow</h1><p>Manages a Data Flow inside an Azure Data Factory.</p>"}