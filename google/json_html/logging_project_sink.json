{"google-logging-project-sink": "<h1 id=\"google_logging_project_sink\">google_logging_project_sink</h1><p>Manages a project-level logging sink. For more information see:</p><ul><li><a href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/projects.sinks\">API documentation</a></li><li>How-to Guides<ul><li><a href=\"https://cloud.google.com/logging/docs/export\">Exporting Logs</a></li></ul></li></ul><p>~&gt; You can specify exclusions for log sinks created by terraform by using the exclusions field of <code>google_logging_folder_sink</code></p><p>~&gt; <strong>Note:</strong> You must have <a href=\"https://cloud.google.com/logging/docs/access-control\">granted the \"Logs Configuration Writer\"</a> IAM role (<code>roles/logging.configWriter</code>) to the credentials used with terraform.</p><p>~&gt; <strong>Note</strong> You must <a href=\"https://console.cloud.google.com/apis/library/cloudresourcemanager.googleapis.com\">enable the Cloud Resource Manager API</a></p>", "example-usage": "<h2 id=\"example-usage\">Example Usage</h2><p>resource \"google_logging_project_sink\" \"my-sink\" {<br />  name = \"my-pubsub-instance-sink\"</p><br /><p># Can export to pubsub, cloud storage, bigquery, log bucket, or another project<br />  destination = \"pubsub.googleapis.com/projects/my-project/topics/instance-activity\"</p><br /><p># Log all WARN or higher severity messages relating to instances<br />  filter = \"resource.type = gce_instance AND severity &gt;= WARNING\"</p><br /><p># Use a unique writer (creates a unique service account used for writing)<br />  unique_writer_identity = true<br />}</p><br /><p>A more complete example follows: this creates a compute instance, as well as a log sink that logs all activity to a<br />cloud storage bucket. Because we are using <code>unique_writer_identity</code>, we must grant it access to the bucket.</p><br /><p>Note that this grant requires the \"Project IAM Admin\" IAM role (<code>roles/resourcemanager.projectIamAdmin</code>) granted to the<br />credentials used with Terraform.</p><br />", "our-logged-compute-instance": "<h1 id=\"our-logged-compute-instance\">Our logged compute instance</h1><p>resource \"google_compute_instance\" \"my-logged-instance\" {<br />  name         = \"my-instance\"<br />  machine_type = \"e2-medium\"<br />  zone         = \"us-central1-a\"</p><p>boot_disk {<br />    initialize_params {<br />      image = \"debian-cloud/debian-11\"<br />    }<br />  }</p><p>network_interface {<br />    network = \"default\"</p><pre><code>access_config {}</code></pre><p>}<br />}</p>", "a-gcs-bucket-to-store-logs-in": "<h1 id=\"a-gcs-bucket-to-store-logs-in\">A gcs bucket to store logs in</h1><p>resource \"google_storage_bucket\" \"gcs-bucket\" {<br />  name     = \"my-unique-logging-bucket\"<br />  location = \"US\"<br />}</p>", "our-sink-this-logs-all-activity-related-to-our-my-logged-instance-instance": "<h1 id=\"our-sink-this-logs-all-activity-related-to-our-my-logged-instance-instance\">Our sink; this logs all activity related to our \"my-logged-instance\" instance</h1><p>resource \"google_logging_project_sink\" \"instance-sink\" {<br />  name        = \"my-instance-sink\"<br />  description = \"some explanation on what this is\"<br />  destination = \"storage.googleapis.com/${google_storage_bucket.gcs-bucket.name}\"<br />  filter      = \"resource.type = gce_instance AND resource.labels.instance_id = \\\"${google_compute_instance.my-logged-instance.instance_id}\\\"\"</p><p>unique_writer_identity = true<br />}</p>", "because-our-sink-uses-a-unique-writer-we-must-grant-that-writer-access-to-the-bucket": "<h1 id=\"because-our-sink-uses-a-unique_writer-we-must-grant-that-writer-access-to-the-bucket\">Because our sink uses a unique_writer, we must grant that writer access to the bucket.</h1><p>resource \"google_project_iam_binding\" \"gcs-bucket-writer\" {<br />  project = \"your-project-id\"<br />  role = \"roles/storage.objectCreator\"</p><p>members = [<br />    google_logging_project_sink.instance-sink.writer_identity,<br />  ]<br />}</p><p>The following example uses <code>exclusions</code> to filter logs that will not be exported. In this example logs are exported to a <a href=\"https://cloud.google.com/logging/docs/buckets\">log bucket</a> and there are 2 exclusions configured</p><p>resource \"google_logging_project_sink\" \"log-bucket\" {<br />  name        = \"my-logging-sink\"<br />  destination = \"logging.googleapis.com/projects/my-project/locations/global/buckets/_Default\"</p><p>exclusions {<br />    name        = \"nsexcllusion1\"<br />    description = \"Exclude logs from namespace-1 in k8s\"<br />    filter      = \"resource.type = k8s_container resource.labels.namespace_name=\\\"namespace-1\\\" \"<br />  }</p><p>exclusions {<br />    name        = \"nsexcllusion2\"<br />    description = \"Exclude logs from namespace-2 in k8s\"<br />    filter      = \"resource.type = k8s_container resource.labels.namespace_name=\\\"namespace-2\\\" \"<br />  }</p><p>unique_writer_identity = true<br />}</p>", "argument-reference": "<h2 id=\"argument-reference\">Argument Reference</h2><p>The following arguments are supported:</p><ul><li><p><code>name</code> - (Required) The name of the logging sink.</p></li><li><p><code>destination</code> - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a<br />    Cloud Storage bucket, a PubSub topic, a BigQuery dataset or a Cloud Logging bucket . Examples:</p><ul><li><code>storage.googleapis.com/[GCS_BUCKET]</code></li><li><code>bigquery.googleapis.com/projects/[PROJECT_ID]/datasets/[DATASET]</code></li><li><code>pubsub.googleapis.com/projects/[PROJECT_ID]/topics/[TOPIC_ID]</code></li><li><code>logging.googleapis.com/projects/[PROJECT_ID]/locations/global/buckets/[BUCKET_ID]</code></li><li><code>logging.googleapis.com/projects/[PROJECT_ID]</code></li></ul><p>The writer associated with the sink must have access to write to the above resource.</p></li><li><p><code>filter</code> - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.<br />    See <a href=\"https://cloud.google.com/logging/docs/view/advanced_filters\">Advanced Log Filters</a> for information on how to<br />    write a filter.</p></li><li><p><code>description</code> - (Optional) A description of this sink. The maximum length of the description is 8000 characters.</p></li><li><p><code>disabled</code> - (Optional) If set to True, then this sink is disabled and it does not export any log entries.</p></li><li><p><code>project</code> - (Optional) The ID of the project to create the sink in. If omitted, the project associated with the provider is<br />    used.</p></li><li><p><code>unique_writer_identity</code> - (Optional) Whether or not to create a unique identity associated with this sink. If <code>false</code><br />    (the default), then the <code>writer_identity</code> used is <code>serviceAccount:cloud-logs@system.gserviceaccount.com</code>. If <code>true</code>,<br />    then a unique service account is created and used for this sink. If you wish to publish logs across projects or utilize<br /><code>bigquery_options</code>, you must set <code>unique_writer_identity</code> to true.</p></li><li><p><code>bigquery_options</code> - (Optional) Options that affect sinks exporting data to BigQuery. Structure <a href=\"#nested_bigquery_options\">documented below</a>.</p></li><li><p><code>exclusions</code> - (Optional) Log entries that match any of the exclusion filters will not be exported. If a log entry is matched by both <code>filter</code> and one of <code>exclusions.filter</code>, it will not be exported.  Can be repeated multiple times for multiple exclusions. Structure is <a href=\"#nested_exclusions\">documented below</a>.</p></li></ul><p><a name=\"nested_bigquery_options\"></a>The <code>bigquery_options</code> block supports:</p><ul><li><code>use_partitioned_tables</code> - (Required) Whether to use <a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">BigQuery's partition tables</a>.<br />    By default, Logging creates dated tables based on the log entries' timestamps, e.g. <code>syslog_20170523</code>. With partitioned<br />    tables the date suffix is no longer present and <a href=\"https://cloud.google.com/bigquery/docs/querying-partitioned-tables\">special query syntax</a><br />    has to be used instead. In both cases, tables are sharded based on UTC timezone.</li></ul><p><a name=\"nested_exclusions\"></a>The <code>exclusions</code> block supports:</p><ul><li><code>name</code> - (Required) A client-assigned identifier, such as <code>load-balancer-exclusion</code>. Identifiers are limited to 100 characters and can include only letters, digits, underscores, hyphens, and periods. First character has to be alphanumeric.</li><li><code>description</code> - (Optional) A description of this exclusion.</li><li><code>filter</code> - (Required) An advanced logs filter that matches the log entries to be excluded. By using the sample function, you can exclude less than 100% of the matching log entries. See <a href=\"https://cloud.google.com/logging/docs/view/advanced_filters\">Advanced Log Filters</a> for information on how to<br />    write a filter.</li><li><code>disabled</code> - (Optional) If set to True, then this exclusion is disabled and it does not exclude any log entries.</li></ul>", "attributes-reference": "<h2 id=\"attributes-reference\">Attributes Reference</h2><p>In addition to the arguments listed above, the following computed attributes are<br />exported:</p><ul><li><p><code>id</code> - an identifier for the resource with format <code>projects/{{project}}/sinks/{{name}}</code></p></li><li><p><code>writer_identity</code> - The identity associated with this sink. This identity must be granted write access to the<br />    configured <code>destination</code>.</p></li></ul>", "import": "<h2 id=\"import\">Import</h2><p>Project-level logging sinks can be imported using their URI, e.g.</p><p>$ terraform import google_logging_project_sink.my_sink projects/my-project/sinks/my-sink</p>", "description": "<h1 id=\"google_logging_project_sink\">google_logging_project_sink</h1><p>Manages a project-level logging sink. For more information see:</p><ul><li><a href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/projects.sinks\">API documentation</a></li><li>How-to Guides<ul><li><a href=\"https://cloud.google.com/logging/docs/export\">Exporting Logs</a></li></ul></li></ul><p>~&gt; You can specify exclusions for log sinks created by terraform by using the exclusions field of <code>google_logging_folder_sink</code></p><p>~&gt; <strong>Note:</strong> You must have <a href=\"https://cloud.google.com/logging/docs/access-control\">granted the \"Logs Configuration Writer\"</a> IAM role (<code>roles/logging.configWriter</code>) to the credentials used with terraform.</p><p>~&gt; <strong>Note</strong> You must <a href=\"https://console.cloud.google.com/apis/library/cloudresourcemanager.googleapis.com\">enable the Cloud Resource Manager API</a></p>"}