{"": "<h1 id=\"-_2\">----------------------------------------------------------------------------</h1><p>subcategory: \"Dataplex\"<br />description: |-<br />  Represents a user-visible job which provides the insights for the related data source.</p><hr />", "auto-generated-code-type-mmv1": "<h1 id=\"auto-generated-code-type-mmv1\"><strong><em>     AUTO GENERATED CODE    </em></strong>    Type: MMv1     ***</h1>", "this-file-is-automatically-generated-by-magic-modules-and-manual": "<h1 id=\"this-file-is-automatically-generated-by-magic-modules-and-manual\">This file is automatically generated by Magic Modules and manual</h1>", "changes-will-be-clobbered-when-the-file-is-regenerated": "<h1 id=\"changes-will-be-clobbered-when-the-file-is-regenerated\">changes will be clobbered when the file is regenerated.</h1>", "please-read-more-about-how-to-change-this-file-in": "<h1 id=\"please-read-more-about-how-to-change-this-file-in\">Please read more about how to change this file in</h1>", "github-contributing-md": "<h1 id=\"githubcontributingmd\">.github/CONTRIBUTING.md.</h1>", "google-dataplex-datascan": "<h1 id=\"google_dataplex_datascan\">google_dataplex_datascan</h1><p>Represents a user-visible job which provides the insights for the related data source.</p><p>To get more information about Datascan, see:</p><ul><li><a href=\"https://cloud.google.com/dataplex/docs/reference/rest\">API documentation</a></li><li>How-to Guides<ul><li><a href=\"https://cloud.google.com/dataplex/docs\">Official Documentation</a></li></ul></li></ul>", "example-usage---dataplex-datascan-basic-profile": "<h2 id=\"example-usage-dataplex-datascan-basic-profile\">Example Usage - Dataplex Datascan Basic Profile</h2><p><br />resource \"google_dataplex_datascan\" \"basic_profile\" {<br />  location     = \"us-central1\"<br />  data_scan_id = \"dataprofile-basic\"</p><p>data {<br />      resource = \"//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare\"<br />  }</p><p>execution_spec {<br />    trigger {<br />      on_demand {}<br />    }<br />  }</p><p>data_profile_spec {}</p><p>project = \"my-project-name\"<br />}<br /></p>", "example-usage---dataplex-datascan-full-profile": "<h2 id=\"example-usage-dataplex-datascan-full-profile\">Example Usage - Dataplex Datascan Full Profile</h2><p><br />resource \"google_dataplex_datascan\" \"full_profile\" {<br />  location     = \"us-central1\"<br />  display_name = \"Full Datascan Profile\"<br />  data_scan_id = \"dataprofile-full\"<br />  description  = \"Example resource - Full Datascan Profile\"<br />  labels = {<br />    author = \"billing\"<br />  }</p><p>data {<br />    resource = \"//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare\"<br />  }</p><p>execution_spec {<br />    trigger {<br />      schedule {<br />        cron = \"TZ=America/New_York 1 1 * <em> </em>\"<br />      }<br />    }<br />  }</p><p>data_profile_spec {<br />    sampling_percent = 80<br />    row_filter = \"word_count &gt; 10\"<br />    include_fields {<br />      field_names = [\"word_count\"]<br />    }<br />    exclude_fields {<br />      field_names = [\"property_type\"]<br />    }<br />    post_scan_actions {<br />      bigquery_export {<br />        results_table = \"//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export\"<br />      }<br />    }<br />  }</p><p>project = \"my-project-name\"</p><p>depends_on = [<br />    google_bigquery_dataset.source<br />  ]<br />}</p><p>resource \"google_bigquery_dataset\" \"source\" {<br />  dataset_id                  = \"dataplex_dataset\"<br />  friendly_name               = \"test\"<br />  description                 = \"This is a test description\"<br />  location                    = \"US\"<br />  delete_contents_on_destroy = true<br />}<br /></p>", "example-usage---dataplex-datascan-basic-quality": "<h2 id=\"example-usage-dataplex-datascan-basic-quality\">Example Usage - Dataplex Datascan Basic Quality</h2><p><br />resource \"google_dataplex_datascan\" \"basic_quality\" {<br />  location     = \"us-central1\"<br />  data_scan_id = \"dataquality-basic\"</p><p>data {<br />    resource = \"//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare\"<br />  }</p><p>execution_spec {<br />    trigger {<br />      on_demand {}<br />    }<br />  }</p><p>data_quality_spec {<br />    rules {<br />      dimension = \"VALIDITY\"<br />      name = \"rule1\"<br />      description = \"rule 1 for validity dimension\"<br />      table_condition_expectation {<br />        sql_expression = \"COUNT(*) &gt; 0\"<br />      }<br />    }<br />  }</p><p>project = \"my-project-name\"<br />}<br /></p>", "example-usage---dataplex-datascan-full-quality": "<h2 id=\"example-usage-dataplex-datascan-full-quality\">Example Usage - Dataplex Datascan Full Quality</h2><p><br />resource \"google_dataplex_datascan\" \"full_quality\" {<br />  location = \"us-central1\"<br />  display_name = \"Full Datascan Quality\"<br />  data_scan_id = \"dataquality-full\"<br />  description = \"Example resource - Full Datascan Quality\"<br />  labels = {<br />    author = \"billing\"<br />  }</p><p>data {<br />    resource = \"//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations\"<br />  }</p><p>execution_spec {<br />    trigger {<br />      schedule {<br />        cron = \"TZ=America/New_York 1 1 * <em> </em>\"<br />      }<br />    }<br />    field = \"modified_date\"<br />  }</p><p>data_quality_spec {<br />    sampling_percent = 5<br />    row_filter = \"station_id &gt; 1000\"<br />    rules {<br />      column = \"address\"<br />      dimension = \"VALIDITY\"<br />      threshold = 0.99<br />      non_null_expectation {}<br />    }</p><pre><code>rules {  column = \"council_district\"  dimension = \"VALIDITY\"  ignore_null = true  threshold = 0.9  range_expectation {    min_value = 1    max_value = 10    strict_min_enabled = true    strict_max_enabled = false  }}rules {  column = \"power_type\"  dimension = \"VALIDITY\"  ignore_null = false  regex_expectation {    regex = \".*solar.*\"  }}rules {  column = \"property_type\"  dimension = \"VALIDITY\"  ignore_null = false  set_expectation {    values = [\"sidewalk\", \"parkland\"]  }}rules {  column = \"address\"  dimension = \"UNIQUENESS\"  uniqueness_expectation {}}rules {  column = \"number_of_docks\"  dimension = \"VALIDITY\"  statistic_range_expectation {    statistic = \"MEAN\"    min_value = 5    max_value = 15    strict_min_enabled = true    strict_max_enabled = true  }}rules {  column = \"footprint_length\"  dimension = \"VALIDITY\"  row_condition_expectation {    sql_expression = \"footprint_length &gt; 0 AND footprint_length &lt;= 10\"  }}rules {  dimension = \"VALIDITY\"  table_condition_expectation {    sql_expression = \"COUNT(*) &gt; 0\"  }}</code></pre><p>}</p><p>project = \"my-project-name\"<br />}<br /></p>", "argument-reference": "<h2 id=\"argument-reference\">Argument Reference</h2><p>The following arguments are supported:</p><ul><li><p><code>data</code> -<br />  (Required)<br />  The data source for DataScan.<br />  Structure is <a href=\"#nested_data\">documented below</a>.</p></li><li><p><code>execution_spec</code> -<br />  (Required)<br />  DataScan execution settings.<br />  Structure is <a href=\"#nested_execution_spec\">documented below</a>.</p></li><li><p><code>location</code> -<br />  (Required)<br />  The location where the data scan should reside.</p></li><li><p><code>data_scan_id</code> -<br />  (Required)<br />  DataScan identifier. Must contain only lowercase letters, numbers and hyphens. Must start with a letter. Must end with a number or a letter.</p></li></ul><p><a name=\"nested_data\"></a>The <code>data</code> block supports:</p><ul><li><p><code>entity</code> -<br />  (Optional)<br />  The Dataplex entity that represents the data source(e.g. BigQuery table) for Datascan.</p></li><li><p><code>resource</code> -<br />  (Optional)<br />  The service-qualified full resource name of the cloud resource for a DataScan job to scan against. The field could be:<br />  (Cloud Storage bucket for DataDiscoveryScan)BigQuery table of type \"TABLE\" for DataProfileScan/DataQualityScan.</p></li></ul><p><a name=\"nested_execution_spec\"></a>The <code>execution_spec</code> block supports:</p><ul><li><p><code>trigger</code> -<br />  (Required)<br />  Spec related to how often and when a scan should be triggered.<br />  Structure is <a href=\"#nested_trigger\">documented below</a>.</p></li><li><p><code>field</code> -<br />  (Optional)<br />  The unnested field (of type Date or Timestamp) that contains values which monotonically increase over time. If not specified, a data scan will run for all data in the table.</p></li></ul><p><a name=\"nested_trigger\"></a>The <code>trigger</code> block supports:</p><ul><li><p><code>on_demand</code> -<br />  (Optional)<br />  The scan runs once via dataScans.run API.</p></li><li><p><code>schedule</code> -<br />  (Optional)<br />  The scan is scheduled to run periodically.<br />  Structure is <a href=\"#nested_schedule\">documented below</a>.</p></li></ul><p><a name=\"nested_schedule\"></a>The <code>schedule</code> block supports:</p><ul><li><code>cron</code> -<br />  (Required)<br />  Cron schedule for running scans periodically. This field is required for Schedule scans.</li></ul><hr /><ul><li><p><code>description</code> -<br />  (Optional)<br />  Description of the scan.</p></li><li><p><code>display_name</code> -<br />  (Optional)<br />  User friendly display name.</p></li><li><p><code>labels</code> -<br />  (Optional)<br />  User-defined labels for the scan. A list of key-&gt;value pairs.</p></li><li><p><code>data_quality_spec</code> -<br />  (Optional)<br />  DataQualityScan related setting.<br />  Structure is <a href=\"#nested_data_quality_spec\">documented below</a>.</p></li><li><p><code>data_profile_spec</code> -<br />  (Optional)<br />  DataProfileScan related setting.<br />  Structure is <a href=\"#nested_data_profile_spec\">documented below</a>.</p></li><li><p><code>project</code> - (Optional) The ID of the project in which the resource belongs.<br />    If it is not provided, the provider project is used.</p></li></ul><p><a name=\"nested_data_quality_spec\"></a>The <code>data_quality_spec</code> block supports:</p><ul><li><p><code>sampling_percent</code> -<br />  (Optional)<br />  The percentage of the records to be selected from the dataset for DataScan.<br />  Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.<br />  Sampling is not applied if <code>sampling_percent</code> is not specified, 0 or 100.</p></li><li><p><code>row_filter</code> -<br />  (Optional)<br />  A filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 &gt;= 0 AND col2 &lt; 10</p></li><li><p><code>post_scan_actions</code> -<br />  (Optional)<br />  Actions to take upon job completion.<br />  Structure is <a href=\"#nested_post_scan_actions\">documented below</a>.</p></li><li><p><code>rules</code> -<br />  (Optional)<br />  The list of rules to evaluate against a data source. At least one rule is required.<br />  Structure is <a href=\"#nested_rules\">documented below</a>.</p></li></ul><p><a name=\"nested_post_scan_actions\"></a>The <code>post_scan_actions</code> block supports:</p><ul><li><code>bigquery_export</code> -<br />  (Optional)<br />  If set, results will be exported to the provided BigQuery table.<br />  Structure is <a href=\"#nested_bigquery_export\">documented below</a>.</li></ul><p><a name=\"nested_bigquery_export\"></a>The <code>bigquery_export</code> block supports:</p><ul><li><code>results_table</code> -<br />  (Optional)<br />  The BigQuery table to export DataQualityScan results to.<br />  Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID</li></ul><p><a name=\"nested_rules\"></a>The <code>rules</code> block supports:</p><ul><li><p><code>column</code> -<br />  (Optional)<br />  The unnested column which this rule is evaluated against.</p></li><li><p><code>ignore_null</code> -<br />  (Optional)<br />  Rows with null values will automatically fail a rule, unless ignoreNull is true. In that case, such null rows are trivially considered passing. Only applicable to ColumnMap rules.</p></li><li><p><code>dimension</code> -<br />  (Required)<br />  The dimension a rule belongs to. Results are also aggregated at the dimension level. Supported dimensions are [\"COMPLETENESS\", \"ACCURACY\", \"CONSISTENCY\", \"VALIDITY\", \"UNIQUENESS\", \"INTEGRITY\"]</p></li><li><p><code>threshold</code> -<br />  (Optional)<br />  The minimum ratio of passing_rows / total_rows required to pass this rule, with a range of [0.0, 1.0]. 0 indicates default value (i.e. 1.0).</p></li><li><p><code>name</code> -<br />  (Optional)<br />  A mutable name for the rule.<br />  The name must contain only letters (a-z, A-Z), numbers (0-9), or hyphens (-).<br />  The maximum length is 63 characters.<br />  Must start with a letter.<br />  Must end with a number or a letter.</p></li><li><p><code>description</code> -<br />  (Optional)<br />  Description of the rule.<br />  The maximum length is 1,024 characters.</p></li><li><p><code>range_expectation</code> -<br />  (Optional)<br />  ColumnMap rule which evaluates whether each column value lies between a specified range.<br />  Structure is <a href=\"#nested_range_expectation\">documented below</a>.</p></li><li><p><code>non_null_expectation</code> -<br />  (Optional)<br />  ColumnMap rule which evaluates whether each column value is null.</p></li><li><p><code>set_expectation</code> -<br />  (Optional)<br />  ColumnMap rule which evaluates whether each column value is contained by a specified set.<br />  Structure is <a href=\"#nested_set_expectation\">documented below</a>.</p></li><li><p><code>regex_expectation</code> -<br />  (Optional)<br />  ColumnMap rule which evaluates whether each column value matches a specified regex.<br />  Structure is <a href=\"#nested_regex_expectation\">documented below</a>.</p></li><li><p><code>uniqueness_expectation</code> -<br />  (Optional)<br />  Row-level rule which evaluates whether each column value is unique.</p></li><li><p><code>statistic_range_expectation</code> -<br />  (Optional)<br />  ColumnAggregate rule which evaluates whether the column aggregate statistic lies between a specified range.<br />  Structure is <a href=\"#nested_statistic_range_expectation\">documented below</a>.</p></li><li><p><code>row_condition_expectation</code> -<br />  (Optional)<br />  Table rule which evaluates whether each row passes the specified condition.<br />  Structure is <a href=\"#nested_row_condition_expectation\">documented below</a>.</p></li><li><p><code>table_condition_expectation</code> -<br />  (Optional)<br />  Table rule which evaluates whether the provided expression is true.<br />  Structure is <a href=\"#nested_table_condition_expectation\">documented below</a>.</p></li></ul><p><a name=\"nested_range_expectation\"></a>The <code>range_expectation</code> block supports:</p><ul><li><p><code>min_value</code> -<br />  (Optional)<br />  The minimum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.</p></li><li><p><code>max_value</code> -<br />  (Optional)<br />  The maximum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.</p></li><li><p><code>strict_min_enabled</code> -<br />  (Optional)<br />  Whether each value needs to be strictly greater than ('&gt;') the minimum, or if equality is allowed.<br />  Only relevant if a minValue has been defined. Default = false.</p></li><li><p><code>strict_max_enabled</code> -<br />  (Optional)<br />  Whether each value needs to be strictly lesser than ('&lt;') the maximum, or if equality is allowed.<br />  Only relevant if a maxValue has been defined. Default = false.</p></li></ul><p><a name=\"nested_set_expectation\"></a>The <code>set_expectation</code> block supports:</p><ul><li><code>values</code> -<br />  (Required)<br />  Expected values for the column value.</li></ul><p><a name=\"nested_regex_expectation\"></a>The <code>regex_expectation</code> block supports:</p><ul><li><code>regex</code> -<br />  (Required)<br />  A regular expression the column value is expected to match.</li></ul><p><a name=\"nested_statistic_range_expectation\"></a>The <code>statistic_range_expectation</code> block supports:</p><ul><li><p><code>statistic</code> -<br />  (Required)<br />  column statistics.<br />  Possible values are: <code>STATISTIC_UNDEFINED</code>, <code>MEAN</code>, <code>MIN</code>, <code>MAX</code>.</p></li><li><p><code>min_value</code> -<br />  (Optional)<br />  The minimum column statistic value allowed for a row to pass this validation.<br />  At least one of minValue and maxValue need to be provided.</p></li><li><p><code>max_value</code> -<br />  (Optional)<br />  The maximum column statistic value allowed for a row to pass this validation.<br />  At least one of minValue and maxValue need to be provided.</p></li><li><p><code>strict_min_enabled</code> -<br />  (Optional)<br />  Whether column statistic needs to be strictly greater than ('&gt;') the minimum, or if equality is allowed.<br />  Only relevant if a minValue has been defined. Default = false.</p></li><li><p><code>strict_max_enabled</code> -<br />  (Optional)<br />  Whether column statistic needs to be strictly lesser than ('&lt;') the maximum, or if equality is allowed.<br />  Only relevant if a maxValue has been defined. Default = false.</p></li></ul><p><a name=\"nested_row_condition_expectation\"></a>The <code>row_condition_expectation</code> block supports:</p><ul><li><code>sql_expression</code> -<br />  (Required)<br />  The SQL expression.</li></ul><p><a name=\"nested_table_condition_expectation\"></a>The <code>table_condition_expectation</code> block supports:</p><ul><li><code>sql_expression</code> -<br />  (Required)<br />  The SQL expression.</li></ul><p><a name=\"nested_data_profile_spec\"></a>The <code>data_profile_spec</code> block supports:</p><ul><li><p><code>sampling_percent</code> -<br />  (Optional)<br />  The percentage of the records to be selected from the dataset for DataScan.<br />  Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.<br />  Sampling is not applied if <code>sampling_percent</code> is not specified, 0 or 100.</p></li><li><p><code>row_filter</code> -<br />  (Optional)<br />  A filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 &gt;= 0 AND col2 &lt; 10</p></li><li><p><code>post_scan_actions</code> -<br />  (Optional)<br />  Actions to take upon job completion.<br />  Structure is <a href=\"#nested_post_scan_actions\">documented below</a>.</p></li><li><p><code>include_fields</code> -<br />  (Optional)<br />  The fields to include in data profile.<br />  If not specified, all fields at the time of profile scan job execution are included, except for ones listed in <code>exclude_fields</code>.<br />  Structure is <a href=\"#nested_include_fields\">documented below</a>.</p></li><li><p><code>exclude_fields</code> -<br />  (Optional)<br />  The fields to exclude from data profile.<br />  If specified, the fields will be excluded from data profile, regardless of <code>include_fields</code> value.<br />  Structure is <a href=\"#nested_exclude_fields\">documented below</a>.</p></li></ul><p><a name=\"nested_post_scan_actions\"></a>The <code>post_scan_actions</code> block supports:</p><ul><li><code>bigquery_export</code> -<br />  (Optional)<br />  If set, results will be exported to the provided BigQuery table.<br />  Structure is <a href=\"#nested_bigquery_export\">documented below</a>.</li></ul><p><a name=\"nested_bigquery_export\"></a>The <code>bigquery_export</code> block supports:</p><ul><li><code>results_table</code> -<br />  (Optional)<br />  The BigQuery table to export DataProfileScan results to.<br />  Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID</li></ul><p><a name=\"nested_include_fields\"></a>The <code>include_fields</code> block supports:</p><ul><li><code>field_names</code> -<br />  (Optional)<br />  Expected input is a list of fully qualified names of fields as in the schema.<br />  Only top-level field names for nested fields are supported.<br />  For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.</li></ul><p><a name=\"nested_exclude_fields\"></a>The <code>exclude_fields</code> block supports:</p><ul><li><code>field_names</code> -<br />  (Optional)<br />  Expected input is a list of fully qualified names of fields as in the schema.<br />  Only top-level field names for nested fields are supported.<br />  For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.</li></ul>", "attributes-reference": "<h2 id=\"attributes-reference\">Attributes Reference</h2><p>In addition to the arguments listed above, the following computed attributes are exported:</p><ul><li><p><code>id</code> - an identifier for the resource with format <code>projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}</code></p></li><li><p><code>name</code> -<br />  The relative resource name of the scan, of the form: projects/{project}/locations/{locationId}/dataScans/{datascan_id}, where project refers to a project_id or project_number and locationId refers to a GCP region.</p></li><li><p><code>uid</code> -<br />  System generated globally unique ID for the scan. This ID will be different if the scan is deleted and re-created with the same name.</p></li><li><p><code>state</code> -<br />  Current state of the DataScan.</p></li><li><p><code>create_time</code> -<br />  The time when the scan was created.</p></li><li><p><code>update_time</code> -<br />  The time when the scan was last updated.</p></li><li><p><code>execution_status</code> -<br />  Status of the data scan execution.<br />  Structure is <a href=\"#nested_execution_status\">documented below</a>.</p></li><li><p><code>type</code> -<br />  The type of DataScan.</p></li><li><p><code>data_quality_result</code> -<br />  (Deprecated)<br />  The result of the data quality scan.<br />  Structure is <a href=\"#nested_data_quality_result\">documented below</a>.</p></li></ul><p>~&gt; <strong>Warning:</strong> <code>data_quality_result</code> is deprecated and will be removed in a future major release.</p><ul><li><code>data_profile_result</code> -<br />  (Deprecated)<br />  The result of the data profile scan.<br />  Structure is <a href=\"#nested_data_profile_result\">documented below</a>.</li></ul><p>~&gt; <strong>Warning:</strong> <code>data_profile_result</code> is deprecated and will be removed in a future major release.</p><p><a name=\"nested_execution_status\"></a>The <code>execution_status</code> block contains:</p><ul><li><p><code>latest_job_end_time</code> -<br />  (Output)<br />  The time when the latest DataScanJob started.</p></li><li><p><code>latest_job_start_time</code> -<br />  (Output)<br />  The time when the latest DataScanJob ended.</p></li></ul><p><a name=\"nested_data_quality_result\"></a>The <code>data_quality_result</code> block contains:</p><ul><li><p><code>passed</code> -<br />  (Output)<br />  Overall data quality result -- true if all rules passed.</p></li><li><p><code>dimensions</code> -<br />  (Optional)<br />  A list of results at the dimension level.<br />  Structure is <a href=\"#nested_dimensions\">documented below</a>.</p></li><li><p><code>rules</code> -<br />  (Output)<br />  A list of all the rules in a job, and their results.<br />  Structure is <a href=\"#nested_rules\">documented below</a>.</p></li><li><p><code>row_count</code> -<br />  (Output)<br />  The count of rows processed.</p></li><li><p><code>scanned_data</code> -<br />  (Output)<br />  The data scanned for this result.<br />  Structure is <a href=\"#nested_scanned_data\">documented below</a>.</p></li></ul><p><a name=\"nested_dimensions\"></a>The <code>dimensions</code> block supports:</p><ul><li><code>passed</code> -<br />  (Optional)<br />  Whether the dimension passed or failed.</li></ul><p><a name=\"nested_rules\"></a>The <code>rules</code> block contains:</p><ul><li><p><code>rule</code> -<br />  (Output)<br />  The rule specified in the DataQualitySpec, as is.<br />  Structure is <a href=\"#nested_rule\">documented below</a>.</p></li><li><p><code>passed</code> -<br />  (Output)<br />  Whether the rule passed or failed.</p></li><li><p><code>evaluated_count</code> -<br />  (Output)<br />  The number of rows a rule was evaluated against. This field is only valid for ColumnMap type rules.<br />  Evaluated count can be configured to either</p></li><li>include all rows (default) - with null rows automatically failing rule evaluation, or</li><li><p>exclude null rows from the evaluatedCount, by setting ignore_nulls = true.</p></li><li><p><code>passed_count</code> -<br />  (Output)<br />  The number of rows which passed a rule evaluation. This field is only valid for ColumnMap type rules.</p></li><li><p><code>null_count</code> -<br />  (Output)<br />  The number of rows with null values in the specified column.</p></li><li><p><code>pass_ratio</code> -<br />  (Output)<br />  The ratio of passedCount / evaluatedCount. This field is only valid for ColumnMap type rules.</p></li><li><p><code>failing_rows_query</code> -<br />  (Output)<br />  The query to find rows that did not pass this rule. Only applies to ColumnMap and RowCondition rules.</p></li></ul><p><a name=\"nested_rule\"></a>The <code>rule</code> block contains:</p><ul><li><p><code>column</code> -<br />  (Optional)<br />  The unnested column which this rule is evaluated against.</p></li><li><p><code>ignore_null</code> -<br />  (Optional)<br />  Rows with null values will automatically fail a rule, unless ignoreNull is true. In that case, such null rows are trivially considered passing. Only applicable to ColumnMap rules.</p></li><li><p><code>dimension</code> -<br />  (Optional)<br />  The dimension a rule belongs to. Results are also aggregated at the dimension level. Supported dimensions are [\"COMPLETENESS\", \"ACCURACY\", \"CONSISTENCY\", \"VALIDITY\", \"UNIQUENESS\", \"INTEGRITY\"]</p></li><li><p><code>threshold</code> -<br />  (Optional)<br />  The minimum ratio of passing_rows / total_rows required to pass this rule, with a range of [0.0, 1.0]. 0 indicates default value (i.e. 1.0).</p></li><li><p><code>range_expectation</code> -<br />  (Output)<br />  ColumnMap rule which evaluates whether each column value lies between a specified range.<br />  Structure is <a href=\"#nested_range_expectation\">documented below</a>.</p></li><li><p><code>non_null_expectation</code> -<br />  (Output)<br />  ColumnMap rule which evaluates whether each column value is null.</p></li><li><p><code>set_expectation</code> -<br />  (Output)<br />  ColumnMap rule which evaluates whether each column value is contained by a specified set.<br />  Structure is <a href=\"#nested_set_expectation\">documented below</a>.</p></li><li><p><code>regex_expectation</code> -<br />  (Output)<br />  ColumnMap rule which evaluates whether each column value matches a specified regex.<br />  Structure is <a href=\"#nested_regex_expectation\">documented below</a>.</p></li><li><p><code>uniqueness_expectation</code> -<br />  (Output)<br />  ColumnAggregate rule which evaluates whether the column has duplicates.</p></li><li><p><code>statistic_range_expectation</code> -<br />  (Output)<br />  ColumnAggregate rule which evaluates whether the column aggregate statistic lies between a specified range.<br />  Structure is <a href=\"#nested_statistic_range_expectation\">documented below</a>.</p></li><li><p><code>row_condition_expectation</code> -<br />  (Output)<br />  Table rule which evaluates whether each row passes the specified condition.<br />  Structure is <a href=\"#nested_row_condition_expectation\">documented below</a>.</p></li><li><p><code>table_condition_expectation</code> -<br />  (Output)<br />  Table rule which evaluates whether the provided expression is true.<br />  Structure is <a href=\"#nested_table_condition_expectation\">documented below</a>.</p></li></ul><p><a name=\"nested_range_expectation\"></a>The <code>range_expectation</code> block contains:</p><ul><li><p><code>min_value</code> -<br />  (Optional)<br />  The minimum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.</p></li><li><p><code>max_value</code> -<br />  (Optional)<br />  The maximum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.</p></li><li><p><code>strict_min_enabled</code> -<br />  (Optional)<br />  Whether each value needs to be strictly greater than ('&gt;') the minimum, or if equality is allowed.<br />  Only relevant if a minValue has been defined. Default = false.</p></li><li><p><code>strict_max_enabled</code> -<br />  (Optional)<br />  Whether each value needs to be strictly lesser than ('&lt;') the maximum, or if equality is allowed.<br />  Only relevant if a maxValue has been defined. Default = false.</p></li></ul><p><a name=\"nested_set_expectation\"></a>The <code>set_expectation</code> block contains:</p><ul><li><code>values</code> -<br />  (Optional)<br />  Expected values for the column value.</li></ul><p><a name=\"nested_regex_expectation\"></a>The <code>regex_expectation</code> block contains:</p><ul><li><code>regex</code> -<br />  (Optional)<br />  A regular expression the column value is expected to match.</li></ul><p><a name=\"nested_statistic_range_expectation\"></a>The <code>statistic_range_expectation</code> block contains:</p><ul><li><p><code>statistic</code> -<br />  (Optional)<br />  column statistics.<br />  Possible values are: <code>STATISTIC_UNDEFINED</code>, <code>MEAN</code>, <code>MIN</code>, <code>MAX</code>.</p></li><li><p><code>min_value</code> -<br />  (Optional)<br />  The minimum column statistic value allowed for a row to pass this validation.<br />  At least one of minValue and maxValue need to be provided.</p></li><li><p><code>max_value</code> -<br />  (Optional)<br />  The maximum column statistic value allowed for a row to pass this validation.<br />  At least one of minValue and maxValue need to be provided.</p></li><li><p><code>strict_min_enabled</code> -<br />  (Optional)<br />  Whether column statistic needs to be strictly greater than ('&gt;') the minimum, or if equality is allowed.<br />  Only relevant if a minValue has been defined. Default = false.</p></li><li><p><code>strict_max_enabled</code> -<br />  (Optional)<br />  Whether column statistic needs to be strictly lesser than ('&lt;') the maximum, or if equality is allowed.<br />  Only relevant if a maxValue has been defined. Default = false.</p></li></ul><p><a name=\"nested_row_condition_expectation\"></a>The <code>row_condition_expectation</code> block contains:</p><ul><li><code>sql_expression</code> -<br />  (Optional)<br />  The SQL expression.</li></ul><p><a name=\"nested_table_condition_expectation\"></a>The <code>table_condition_expectation</code> block contains:</p><ul><li><code>sql_expression</code> -<br />  (Optional)<br />  The SQL expression.</li></ul><p><a name=\"nested_scanned_data\"></a>The <code>scanned_data</code> block contains:</p><ul><li><code>incremental_field</code> -<br />  (Optional)<br />  The range denoted by values of an incremental field<br />  Structure is <a href=\"#nested_incremental_field\">documented below</a>.</li></ul><p><a name=\"nested_incremental_field\"></a>The <code>incremental_field</code> block supports:</p><ul><li><p><code>field</code> -<br />  (Optional)<br />  The field that contains values which monotonically increases over time (e.g. a timestamp column).</p></li><li><p><code>start</code> -<br />  (Optional)<br />  Value that marks the start of the range.</p></li><li><p><code>end</code> -<br />  (Optional)<br />  Value that marks the end of the range.</p></li></ul><p><a name=\"nested_data_profile_result\"></a>The <code>data_profile_result</code> block contains:</p><ul><li><p><code>row_count</code> -<br />  (Optional)<br />  The count of rows scanned.</p></li><li><p><code>profile</code> -<br />  (Output)<br />  The profile information per field.<br />  Structure is <a href=\"#nested_profile\">documented below</a>.</p></li><li><p><code>scanned_data</code> -<br />  (Output)<br />  The data scanned for this result.<br />  Structure is <a href=\"#nested_scanned_data\">documented below</a>.</p></li></ul><p><a name=\"nested_profile\"></a>The <code>profile</code> block contains:</p><ul><li><code>fields</code> -<br />  (Optional)<br />  List of fields with structural and profile information for each field.<br />  Structure is <a href=\"#nested_fields\">documented below</a>.</li></ul><p><a name=\"nested_fields\"></a>The <code>fields</code> block supports:</p><ul><li><p><code>name</code> -<br />  (Optional)<br />  The name of the field.</p></li><li><p><code>type</code> -<br />  (Optional)<br />  The field data type.</p></li><li><p><code>mode</code> -<br />  (Optional)<br />  The mode of the field. Possible values include:</p></li><li>REQUIRED, if it is a required field.</li><li>NULLABLE, if it is an optional field.</li><li><p>REPEATED, if it is a repeated field.</p></li><li><p><code>profile</code> -<br />  (Optional)<br />  Profile information for the corresponding field.<br />  Structure is <a href=\"#nested_profile\">documented below</a>.</p></li></ul><p><a name=\"nested_profile\"></a>The <code>profile</code> block supports:</p><ul><li><p><code>null_ratio</code> -<br />  (Output)<br />  Ratio of rows with null value against total scanned rows.</p></li><li><p><code>distinct_ratio</code> -<br />  (Optional)<br />  Ratio of rows with distinct values against total scanned rows. Not available for complex non-groupable field type RECORD and fields with REPEATABLE mode.</p></li><li><p><code>top_n_values</code> -<br />  (Optional)<br />  The list of top N non-null values and number of times they occur in the scanned data. N is 10 or equal to the number of distinct values in the field, whichever is smaller. Not available for complex non-groupable field type RECORD and fields with REPEATABLE mode.<br />  Structure is <a href=\"#nested_top_n_values\">documented below</a>.</p></li><li><p><code>string_profile</code> -<br />  (Output)<br />  String type field information.<br />  Structure is <a href=\"#nested_string_profile\">documented below</a>.</p></li><li><p><code>integer_profile</code> -<br />  (Output)<br />  Integer type field information.<br />  Structure is <a href=\"#nested_integer_profile\">documented below</a>.</p></li><li><p><code>double_profile</code> -<br />  (Output)<br />  Double type field information.<br />  Structure is <a href=\"#nested_double_profile\">documented below</a>.</p></li></ul><p><a name=\"nested_top_n_values\"></a>The <code>top_n_values</code> block supports:</p><ul><li><p><code>value</code> -<br />  (Optional)<br />  String value of a top N non-null value.</p></li><li><p><code>count</code> -<br />  (Optional)<br />  Count of the corresponding value in the scanned data.</p></li></ul><p><a name=\"nested_string_profile\"></a>The <code>string_profile</code> block contains:</p><ul><li><p><code>min_length</code> -<br />  (Optional)<br />  Minimum length of non-null values in the scanned data.</p></li><li><p><code>max_length</code> -<br />  (Optional)<br />  Maximum length of non-null values in the scanned data.</p></li><li><p><code>average_length</code> -<br />  (Optional)<br />  Average length of non-null values in the scanned data.</p></li></ul><p><a name=\"nested_integer_profile\"></a>The <code>integer_profile</code> block contains:</p><ul><li><p><code>average</code> -<br />  (Optional)<br />  Average of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>standard_deviation</code> -<br />  (Optional)<br />  Standard deviation of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>min</code> -<br />  (Optional)<br />  Minimum of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>quartiles</code> -<br />  (Optional)<br />  A quartile divides the number of data points into four parts, or quarters, of more-or-less equal size. Three main quartiles used are: The first quartile (Q1) splits off the lowest 25% of data from the highest 75%. It is also known as the lower or 25th empirical quartile, as 25% of the data is below this point. The second quartile (Q2) is the median of a data set. So, 50% of the data lies below this point. The third quartile (Q3) splits off the highest 25% of data from the lowest 75%. It is known as the upper or 75th empirical quartile, as 75% of the data lies below this point. Here, the quartiles is provided as an ordered list of quartile values for the scanned data, occurring in order Q1, median, Q3.</p></li><li><p><code>max</code> -<br />  (Optional)<br />  Maximum of non-null values in the scanned data. NaN, if the field has a NaN.</p></li></ul><p><a name=\"nested_double_profile\"></a>The <code>double_profile</code> block contains:</p><ul><li><p><code>average</code> -<br />  (Optional)<br />  Average of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>standard_deviation</code> -<br />  (Optional)<br />  Standard deviation of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>min</code> -<br />  (Optional)<br />  Minimum of non-null values in the scanned data. NaN, if the field has a NaN.</p></li><li><p><code>quartiles</code> -<br />  (Optional)<br />  A quartile divides the number of data points into four parts, or quarters, of more-or-less equal size. Three main quartiles used are: The first quartile (Q1) splits off the lowest 25% of data from the highest 75%. It is also known as the lower or 25th empirical quartile, as 25% of the data is below this point. The second quartile (Q2) is the median of a data set. So, 50% of the data lies below this point. The third quartile (Q3) splits off the highest 25% of data from the lowest 75%. It is known as the upper or 75th empirical quartile, as 75% of the data lies below this point. Here, the quartiles is provided as an ordered list of quartile values for the scanned data, occurring in order Q1, median, Q3.</p></li><li><p><code>max</code> -<br />  (Optional)<br />  Maximum of non-null values in the scanned data. NaN, if the field has a NaN.</p></li></ul><p><a name=\"nested_scanned_data\"></a>The <code>scanned_data</code> block contains:</p><ul><li><code>incremental_field</code> -<br />  (Optional)<br />  The range denoted by values of an incremental field<br />  Structure is <a href=\"#nested_incremental_field\">documented below</a>.</li></ul><p><a name=\"nested_incremental_field\"></a>The <code>incremental_field</code> block supports:</p><ul><li><p><code>field</code> -<br />  (Optional)<br />  The field that contains values which monotonically increases over time (e.g. a timestamp column).</p></li><li><p><code>start</code> -<br />  (Optional)<br />  Value that marks the start of the range.</p></li><li><p><code>end</code> -<br />  (Optional)<br />  Value that marks the end of the range.</p></li></ul>", "timeouts": "<h2 id=\"timeouts\">Timeouts</h2><p>This resource provides the following<br /><a href=\"https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts\">Timeouts</a> configuration options:</p><ul><li><code>create</code> - Default is 5 minutes.</li><li><code>update</code> - Default is 5 minutes.</li><li><code>delete</code> - Default is 5 minutes.</li></ul>", "import": "<h2 id=\"import\">Import</h2><p>Datascan can be imported using any of these accepted formats:</p><p><code>$ terraform import google_dataplex_datascan.default projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}$ terraform import google_dataplex_datascan.default {{project}}/{{location}}/{{data_scan_id}}$ terraform import google_dataplex_datascan.default {{location}}/{{data_scan_id}}$ terraform import google_dataplex_datascan.default {{data_scan_id}}</code></p>", "user-project-overrides": "<h2 id=\"user-project-overrides\">User Project Overrides</h2><p>This resource supports <a href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#user_project_override\">User Project Overrides</a>.</p>", "description": "<h1 id=\"google_dataplex_datascan\">google_dataplex_datascan</h1><p>Represents a user-visible job which provides the insights for the related data source.</p><p>To get more information about Datascan, see:</p><ul><li><a href=\"https://cloud.google.com/dataplex/docs/reference/rest\">API documentation</a></li><li>How-to Guides<ul><li><a href=\"https://cloud.google.com/dataplex/docs\">Official Documentation</a></li></ul></li></ul>"}